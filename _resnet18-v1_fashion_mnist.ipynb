{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion MNIST example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Make pipeline using Tensorflow Dataset API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./fashion_mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting ./fashion_mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./fashion_mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./fashion_mnist\\t10k-labels-idx1-ubyte.gz\n",
      "label =  2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnist_folder = './fashion_mnist'\n",
    "mnist = input_data.read_data_sets(mnist_folder, one_hot=True)\n",
    "\n",
    "train_data = tf.data.Dataset.from_tensor_slices((mnist.train.images, mnist.train.labels))\n",
    "val_data = tf.data.Dataset.from_tensor_slices((mnist.validation.images, mnist.validation.labels))\n",
    "test_data = tf.data.Dataset.from_tensor_slices((mnist.test.images, mnist.test.labels))\n",
    "\n",
    "index = 100\n",
    "print(\"label = \", np.argmax(mnist.train.labels[index]))\n",
    "plt.imshow(mnist.train.images[index].reshape(28, 28), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "n_samples = 55000\n",
    "n_test = 10000\n",
    "n_classes = 10\n",
    "batch_size = 128\n",
    "is_training = False\n",
    "_BATCH_NORM_DECAY = 0.997\n",
    "_BATCH_NORM_EPSILON = 1e-5\n",
    "\n",
    "gstep = tf.Variable(0, dtype=tf.int32, trainable=False, name='global_step')\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "_seed = tf.set_random_seed(1777)\n",
    "\n",
    "def augmentation(image, label):\n",
    "    with tf.name_scope('augmentation'):\n",
    "        image = tf.reshape(image, shape=[28, 28, 1])\n",
    "        image = tf.image.random_flip_left_right(image, seed=_seed) # random vertical flip\n",
    "        image = tf.image.random_flip_up_down(image, seed=_seed) # random horizeontal flip\n",
    "        \n",
    "        # random rotate an image counter-clockwise by 90 degrees.\n",
    "        rnd_rot90 = tf.cast(tf.random_uniform([], maxval=2, dtype=tf.int32, seed=_seed), tf.bool)\n",
    "        rnd_degree = tf.random_uniform([], maxval=3, dtype=tf.int32, seed=_seed)\n",
    "        image = tf.cond(rnd_rot90,\n",
    "                    lambda: tf.image.rot90(image, k=rnd_degree),\n",
    "                    lambda: tf.identity(image))\n",
    "        \n",
    "        # random crop\n",
    "        ori_image_shape = tf.shape(image)\n",
    "        rnd_crop = tf.random_uniform([], maxval=10, dtype=tf.int32, seed=_seed)\n",
    "        crop_size = 28 + rnd_crop\n",
    "        image = tf.image.resize_images(image, [crop_size, crop_size])\n",
    "        image = tf.random_crop(image, ori_image_shape, seed=_seed)\n",
    "        image = tf.reshape(image, shape=[784])\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Dataset'):\n",
    "    train_aug_data = train_data.map(augmentation).shuffle(55000).batch(batch_size)\n",
    "    val_data = val_data.batch(batch_size)\n",
    "    test_data = test_data.batch(batch_size)\n",
    "    \n",
    "    iterator = tf.data.Iterator.from_structure(train_aug_data.output_types,\n",
    "                                               train_aug_data.output_shapes)\n",
    "    x_image, y_label = iterator.get_next()\n",
    "\n",
    "    train_init = iterator.make_initializer(train_aug_data)\n",
    "    val_init = iterator.make_initializer(val_data)\n",
    "    test_init = iterator.make_initializer(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build model (refer to [tensorflow official resnet](https://github.com/tensorflow/models/blob/master/official/resnet/resnet_model.py) and [[2]](https://github.com/kefth/fashion-mnist/blob/master/model.py))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet v1\n",
    "def resnet_block(inputs, _filters, _strides=1, projection_shortcut=False):   \n",
    "    if projection_shortcut:\n",
    "        shortcut = tf.layers.conv2d(inputs, _filters, 1, _strides, 'valid', 'channels_first', use_bias=False,\n",
    "                                    kernel_initializer=tf.variance_scaling_initializer())\n",
    "        shortcut = tf.layers.batch_normalization(shortcut, 1, _BATCH_NORM_DECAY, _BATCH_NORM_EPSILON,\n",
    "                                                 training=is_training)\n",
    "        print('use projection shortcut')\n",
    "    else:\n",
    "        shortcut = tf.identity(inputs)\n",
    "    print('shortcut shape : {}'.format(np.shape(shortcut)))\n",
    "    \n",
    "    # if stride is not 1, add 'little' padding\n",
    "    if not _strides == 1:\n",
    "        out = tf.pad(inputs, [[0, 0], [0, 0], [1, 1], [1, 1]])\n",
    "        # [[0, 0], [0, 0], [1, 1], [1, 1]] pad will added\n",
    "        # channels_first data format : [batch, channels, height_in, width_in]\n",
    "    else:\n",
    "        out = tf.identity(inputs)\n",
    "    \n",
    "    out = tf.layers.conv2d(out, _filters, 3, _strides,\n",
    "                           'same' if _strides == 1 else 'valid', 'channels_first',\n",
    "                           use_bias=False, kernel_initializer=tf.variance_scaling_initializer())\n",
    "    out = tf.layers.batch_normalization(out, 1, _BATCH_NORM_DECAY, _BATCH_NORM_EPSILON,\n",
    "                                           training=is_training)\n",
    "    out = tf.nn.relu(out)\n",
    "    out = tf.layers.conv2d(out, _filters, 3, 1, 'same', 'channels_first',\n",
    "                           use_bias=False, kernel_initializer=tf.variance_scaling_initializer())\n",
    "    out = tf.layers.batch_normalization(out, 1, _BATCH_NORM_DECAY, _BATCH_NORM_EPSILON,\n",
    "                                        training=is_training)\n",
    "    out += shortcut\n",
    "    out = tf.nn.relu(out)\n",
    "    print('ResNet block output shape : {}'.format(np.shape(out)))\n",
    "    return out\n",
    "\n",
    "def avg_pooling(inputs):\n",
    "    shape = inputs.get_shape().as_list()\n",
    "    in_channel = [shape[2], shape[3]] # if not channels_first, then (shape[1], shape[2])\n",
    "    \n",
    "    out = tf.layers.average_pooling2d(inputs, in_channel, 1, 'valid', 'channels_first')\n",
    "    \n",
    "    print('Average pooling output shape : {}'.format(np.shape(out)))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape : (?, 1, 28, 28)\n",
      "shortcut shape : (?, 64, 28, 28)\n",
      "ResNet block output shape : (?, 64, 28, 28)\n",
      "shortcut shape : (?, 64, 28, 28)\n",
      "ResNet block output shape : (?, 64, 28, 28)\n",
      "use projection shortcut\n",
      "shortcut shape : (?, 128, 14, 14)\n",
      "ResNet block output shape : (?, 128, 14, 14)\n",
      "shortcut shape : (?, 128, 14, 14)\n",
      "ResNet block output shape : (?, 128, 14, 14)\n",
      "use projection shortcut\n",
      "shortcut shape : (?, 256, 7, 7)\n",
      "ResNet block output shape : (?, 256, 7, 7)\n",
      "shortcut shape : (?, 256, 7, 7)\n",
      "ResNet block output shape : (?, 256, 7, 7)\n",
      "Average pooling output shape : (?, 256, 1, 1)\n",
      "after flatten output shape : (?, 256)\n"
     ]
    }
   ],
   "source": [
    "# Resnet 18-layer like model for fashion mnist\n",
    "image = tf.reshape(tensor=x_image, shape=[-1, 28, 28, 1])\n",
    "\n",
    "# for boost GPU processing | change data format to NCHW (Tensorflow defalut is NHWC)\n",
    "resnet = tf.transpose(image, [0, 3, 1, 2])\n",
    "print('input shape : {}'.format(np.shape(resnet)))\n",
    "\n",
    "resnet = tf.layers.conv2d(resnet, 64, 3, 1, 'same', 'channels_first', use_bias=False, \n",
    "                          kernel_initializer=tf.variance_scaling_initializer())\n",
    "resnet = tf.layers.batch_normalization(resnet, 1, _BATCH_NORM_DECAY, _BATCH_NORM_EPSILON,\n",
    "                                       training=is_training)\n",
    "resnet = tf.nn.relu(resnet)\n",
    "\n",
    "# 1st ResNet block \n",
    "resnet = resnet_block(resnet, 64)\n",
    "resnet = resnet_block(resnet, 64)\n",
    "# output shape [-1, 28, 28, 64]\n",
    "\n",
    "# 2nd ResNet block\n",
    "resnet = resnet_block(resnet, 128, 2, projection_shortcut=True)\n",
    "resnet = resnet_block(resnet, 128)\n",
    "# output shape [-1, 14, 14, 128]\n",
    "\n",
    "# 3rd ResNet block\n",
    "resnet = resnet_block(resnet, 256, 2, projection_shortcut=True)\n",
    "resnet = resnet_block(resnet, 256)\n",
    "# output shape [-1, 7, 7, 256]\n",
    "\n",
    "resnet = avg_pooling(resnet)\n",
    "# output shape [-1, 1, 1, 256]\n",
    "\n",
    "resnet = tf.layers.flatten(resnet)\n",
    "print('after flatten output shape : {}'.format(np.shape(resnet)))\n",
    "# output shape [-1, 256]\n",
    "logits = tf.layers.dense(resnet, n_classes, name='Logits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Loss Function / Optimizer / Prediction / Tensorboard summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('loss'):\n",
    "    entropy = tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_label, logits=logits)\n",
    "    loss = tf.reduce_mean(entropy, name='loss')\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(lr).minimize(loss)\n",
    "\n",
    "with tf.name_scope('predict'):\n",
    "    preds = tf.nn.softmax(logits)\n",
    "    correct_preds = tf.equal(tf.argmax(preds, 1), tf.argmax(y_label, 1))\n",
    "    accuracy = tf.reduce_sum(tf.cast(correct_preds, tf.float32))\n",
    "    \n",
    "with tf.name_scope('summaries'):\n",
    "    tf.summary.scalar('loss', loss)\n",
    "    tf.summary.scalar('accuracy', accuracy)\n",
    "    summary_op = tf.summary.merge_all()\n",
    "    \n",
    "saver = tf.train.Saver(tf.global_variables())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training & Test our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Start learning rate is 0.001 ---\n",
      "Epoch 1: loss = 0.009096 | Took : 53.8015 sec\n",
      "Validation Accuracy 0.7868\n",
      "Epoch 2: loss = 0.005315 | Took : 51.3775 sec\n",
      "Validation Accuracy 0.8372\n",
      "Epoch 3: loss = 0.004297 | Took : 50.7138 sec\n",
      "Validation Accuracy 0.8728\n",
      "Epoch 4: loss = 0.003777 | Took : 50.7884 sec\n",
      "Validation Accuracy 0.8858\n",
      "Epoch 5: loss = 0.003525 | Took : 50.8646 sec\n",
      "Validation Accuracy 0.8890\n",
      "Epoch 6: loss = 0.003291 | Took : 50.6219 sec\n",
      "Validation Accuracy 0.8778\n",
      "Epoch 7: loss = 0.003104 | Took : 50.8499 sec\n",
      "Validation Accuracy 0.8942\n",
      "Epoch 8: loss = 0.002968 | Took : 51.0539 sec\n",
      "Validation Accuracy 0.8906\n",
      "Epoch 9: loss = 0.002866 | Took : 50.8257 sec\n",
      "Validation Accuracy 0.9076\n",
      "Epoch 10: loss = 0.002784 | Took : 50.6428 sec\n",
      "Validation Accuracy 0.8962\n",
      "*** Test Accuracy 0.8879 ***\n",
      "Epoch 11: loss = 0.002662 | Took : 50.7043 sec\n",
      "Validation Accuracy 0.9034\n",
      "Epoch 12: loss = 0.002616 | Took : 50.9357 sec\n",
      "Validation Accuracy 0.9058\n",
      "Epoch 13: loss = 0.002576 | Took : 50.7650 sec\n",
      "Validation Accuracy 0.9118\n",
      "Epoch 14: loss = 0.002487 | Took : 50.9676 sec\n",
      "Validation Accuracy 0.9036\n",
      "Epoch 15: loss = 0.002429 | Took : 50.5935 sec\n",
      "Validation Accuracy 0.9138\n",
      "Epoch 16: loss = 0.002402 | Took : 50.9127 sec\n",
      "Validation Accuracy 0.9140\n",
      "Epoch 17: loss = 0.002354 | Took : 50.8469 sec\n",
      "Validation Accuracy 0.9118\n",
      "Epoch 18: loss = 0.002282 | Took : 51.0136 sec\n",
      "Validation Accuracy 0.9146\n",
      "Epoch 19: loss = 0.002247 | Took : 50.6455 sec\n",
      "Validation Accuracy 0.9196\n",
      "Epoch 20: loss = 0.002189 | Took : 50.8189 sec\n",
      "Validation Accuracy 0.9178\n",
      "*** Test Accuracy 0.9130 ***\n",
      "Epoch 21: loss = 0.002192 | Took : 50.6585 sec\n",
      "Validation Accuracy 0.9200\n",
      "Epoch 22: loss = 0.002123 | Took : 50.8444 sec\n",
      "Validation Accuracy 0.9246\n",
      "Epoch 23: loss = 0.002144 | Took : 50.9209 sec\n",
      "Validation Accuracy 0.9228\n",
      "Epoch 24: loss = 0.002079 | Took : 50.7327 sec\n",
      "Validation Accuracy 0.9216\n",
      "Epoch 25: loss = 0.002055 | Took : 50.6991 sec\n",
      "Validation Accuracy 0.9270\n",
      "Epoch 26: loss = 0.002044 | Took : 50.6949 sec\n",
      "Validation Accuracy 0.9238\n",
      "Epoch 27: loss = 0.002005 | Took : 50.7713 sec\n",
      "Validation Accuracy 0.9272\n",
      "Epoch 28: loss = 0.001968 | Took : 50.6972 sec\n",
      "Validation Accuracy 0.9216\n",
      "Epoch 29: loss = 0.001959 | Took : 50.9660 sec\n",
      "Validation Accuracy 0.9266\n",
      "Epoch 30: loss = 0.001894 | Took : 50.7471 sec\n",
      "Validation Accuracy 0.9282\n",
      "*** Test Accuracy 0.9225 ***\n",
      "Epoch 31: loss = 0.001915 | Took : 50.6508 sec\n",
      "Validation Accuracy 0.9242\n",
      "Epoch 32: loss = 0.001887 | Took : 51.2030 sec\n",
      "Validation Accuracy 0.9284\n",
      "Epoch 33: loss = 0.001864 | Took : 50.7186 sec\n",
      "Validation Accuracy 0.9302\n",
      "Epoch 34: loss = 0.001856 | Took : 50.8564 sec\n",
      "Validation Accuracy 0.9266\n",
      "Epoch 35: loss = 0.001828 | Took : 50.9122 sec\n",
      "Validation Accuracy 0.9242\n",
      "Epoch 36: loss = 0.001827 | Took : 50.6987 sec\n",
      "Validation Accuracy 0.9278\n",
      "Epoch 37: loss = 0.001788 | Took : 50.7836 sec\n",
      "Validation Accuracy 0.9322\n",
      "Epoch 38: loss = 0.001815 | Took : 50.9269 sec\n",
      "Validation Accuracy 0.9290\n",
      "Epoch 39: loss = 0.001774 | Took : 50.7082 sec\n",
      "Validation Accuracy 0.9270\n",
      "Epoch 40: loss = 0.001761 | Took : 51.0340 sec\n",
      "Validation Accuracy 0.9262\n",
      "*** Test Accuracy 0.9191 ***\n",
      "Epoch 41: loss = 0.001725 | Took : 51.0467 sec\n",
      "Validation Accuracy 0.9346\n",
      "Epoch 42: loss = 0.001713 | Took : 50.9996 sec\n",
      "Validation Accuracy 0.9306\n",
      "Epoch 43: loss = 0.001730 | Took : 51.1133 sec\n",
      "Validation Accuracy 0.9280\n",
      "Epoch 44: loss = 0.001691 | Took : 51.1433 sec\n",
      "Validation Accuracy 0.9298\n",
      "Epoch 45: loss = 0.001678 | Took : 51.2063 sec\n",
      "Validation Accuracy 0.9304\n",
      "Epoch 46: loss = 0.001660 | Took : 51.1167 sec\n",
      "Validation Accuracy 0.9342\n",
      "Epoch 47: loss = 0.001682 | Took : 50.8824 sec\n",
      "Validation Accuracy 0.9340\n",
      "Epoch 48: loss = 0.001654 | Took : 50.8252 sec\n",
      "Validation Accuracy 0.9284\n",
      "Epoch 49: loss = 0.001618 | Took : 50.9802 sec\n",
      "Validation Accuracy 0.9314\n",
      "Epoch 50: loss = 0.001622 | Took : 50.8903 sec\n",
      "Validation Accuracy 0.9322\n",
      "*** Test Accuracy 0.9311 ***\n",
      "Epoch 51: loss = 0.001632 | Took : 50.7644 sec\n",
      "Validation Accuracy 0.9340\n",
      "Epoch 52: loss = 0.001614 | Took : 50.9647 sec\n",
      "Validation Accuracy 0.9312\n",
      "Epoch 53: loss = 0.001579 | Took : 50.9232 sec\n",
      "Validation Accuracy 0.9266\n",
      "Epoch 54: loss = 0.001591 | Took : 50.8895 sec\n",
      "Validation Accuracy 0.9234\n",
      "Epoch 55: loss = 0.001594 | Took : 50.7662 sec\n",
      "Validation Accuracy 0.9322\n",
      "Epoch 56: loss = 0.001554 | Took : 50.9985 sec\n",
      "Validation Accuracy 0.9352\n",
      "Epoch 57: loss = 0.001558 | Took : 50.9299 sec\n",
      "Validation Accuracy 0.9346\n",
      "Epoch 58: loss = 0.001535 | Took : 50.8343 sec\n",
      "Validation Accuracy 0.9354\n",
      "Epoch 59: loss = 0.001542 | Took : 51.0152 sec\n",
      "Validation Accuracy 0.9320\n",
      "Epoch 60: loss = 0.001528 | Took : 50.8752 sec\n",
      "Validation Accuracy 0.9308\n",
      "*** Test Accuracy 0.9244 ***\n",
      "Epoch 61: loss = 0.001509 | Took : 50.8591 sec\n",
      "Validation Accuracy 0.9300\n",
      "Epoch 62: loss = 0.001507 | Took : 50.6875 sec\n",
      "Validation Accuracy 0.9358\n",
      "Epoch 63: loss = 0.001489 | Took : 50.8904 sec\n",
      "Validation Accuracy 0.9300\n",
      "Epoch 64: loss = 0.001470 | Took : 50.7233 sec\n",
      "Validation Accuracy 0.9334\n",
      "Epoch 65: loss = 0.001485 | Took : 50.7652 sec\n",
      "Validation Accuracy 0.9334\n",
      "Epoch 66: loss = 0.001469 | Took : 50.9221 sec\n",
      "Validation Accuracy 0.9336\n",
      "Epoch 67: loss = 0.001480 | Took : 50.8447 sec\n",
      "Validation Accuracy 0.9360\n",
      "Epoch 68: loss = 0.001462 | Took : 50.9218 sec\n",
      "Validation Accuracy 0.9356\n",
      "Epoch 69: loss = 0.001460 | Took : 50.8424 sec\n",
      "Validation Accuracy 0.9338\n",
      "Epoch 70: loss = 0.001430 | Took : 50.9867 sec\n",
      "Validation Accuracy 0.9318\n",
      "*** Test Accuracy 0.9289 ***\n",
      "Epoch 71: loss = 0.001440 | Took : 50.8993 sec\n",
      "Validation Accuracy 0.9336\n",
      "Epoch 72: loss = 0.001422 | Took : 50.8442 sec\n",
      "Validation Accuracy 0.9354\n",
      "Epoch 73: loss = 0.001406 | Took : 51.1436 sec\n",
      "Validation Accuracy 0.9360\n",
      "Epoch 74: loss = 0.001425 | Took : 50.5919 sec\n",
      "Validation Accuracy 0.9376\n",
      "Epoch 75: loss = 0.001406 | Took : 50.9157 sec\n",
      "Validation Accuracy 0.9368\n",
      "Epoch 76: loss = 0.001385 | Took : 51.9692 sec\n",
      "Validation Accuracy 0.9308\n",
      "Epoch 77: loss = 0.001416 | Took : 54.2774 sec\n",
      "Validation Accuracy 0.9348\n",
      "Epoch 78: loss = 0.001391 | Took : 55.1234 sec\n",
      "Validation Accuracy 0.9380\n",
      "Epoch 79: loss = 0.001351 | Took : 57.3650 sec\n",
      "Validation Accuracy 0.9302\n",
      "Epoch 80: loss = 0.001389 | Took : 54.7281 sec\n",
      "Validation Accuracy 0.9338\n",
      "*** Test Accuracy 0.9285 ***\n",
      "Epoch 81: loss = 0.001370 | Took : 54.8008 sec\n",
      "Validation Accuracy 0.9346\n",
      "Epoch 82: loss = 0.001360 | Took : 54.9627 sec\n",
      "Validation Accuracy 0.9336\n",
      "Epoch 83: loss = 0.001344 | Took : 55.0702 sec\n",
      "Validation Accuracy 0.9356\n",
      "Epoch 84: loss = 0.001353 | Took : 55.7880 sec\n",
      "Validation Accuracy 0.9374\n",
      "Epoch 85: loss = 0.001340 | Took : 57.0898 sec\n",
      "Validation Accuracy 0.9402\n",
      "Epoch 86: loss = 0.001335 | Took : 54.8139 sec\n",
      "Validation Accuracy 0.9354\n",
      "Epoch 87: loss = 0.001313 | Took : 55.0218 sec\n",
      "Validation Accuracy 0.9414\n",
      "Epoch 88: loss = 0.001308 | Took : 54.5935 sec\n",
      "Validation Accuracy 0.9362\n",
      "Epoch 89: loss = 0.001307 | Took : 54.4724 sec\n",
      "Validation Accuracy 0.9374\n",
      "Epoch 90: loss = 0.001322 | Took : 55.2543 sec\n",
      "Validation Accuracy 0.9352\n",
      "*** Test Accuracy 0.9283 ***\n",
      "Epoch 91: loss = 0.001297 | Took : 49.9630 sec\n",
      "Validation Accuracy 0.9348\n",
      "Epoch 92: loss = 0.001295 | Took : 49.9068 sec\n",
      "Validation Accuracy 0.9390\n",
      "Epoch 93: loss = 0.001259 | Took : 49.8527 sec\n",
      "Validation Accuracy 0.9384\n",
      "Epoch 94: loss = 0.001270 | Took : 49.8316 sec\n",
      "Validation Accuracy 0.9398\n",
      "Epoch 95: loss = 0.001281 | Took : 49.9258 sec\n",
      "Validation Accuracy 0.9388\n",
      "Epoch 96: loss = 0.001272 | Took : 50.3299 sec\n",
      "Validation Accuracy 0.9374\n",
      "Epoch 97: loss = 0.001244 | Took : 49.8486 sec\n",
      "Validation Accuracy 0.9390\n",
      "Epoch 98: loss = 0.001229 | Took : 49.8687 sec\n",
      "Validation Accuracy 0.9366\n",
      "Epoch 99: loss = 0.001264 | Took : 49.9198 sec\n",
      "Validation Accuracy 0.9396\n",
      "Epoch 100: loss = 0.001219 | Took : 49.8677 sec\n",
      "Validation Accuracy 0.9410\n",
      "*** Test Accuracy 0.9364 ***\n",
      "--- Decrease learning rate to 0.0001 ---\n",
      "Epoch 101: loss = 0.001237 | Took : 49.8326 sec\n",
      "Validation Accuracy 0.9388\n",
      "Epoch 102: loss = 0.001249 | Took : 50.5736 sec\n",
      "Validation Accuracy 0.9396\n",
      "Epoch 103: loss = 0.001216 | Took : 49.8968 sec\n",
      "Validation Accuracy 0.9404\n",
      "Epoch 104: loss = 0.001229 | Took : 49.8135 sec\n",
      "Validation Accuracy 0.9358\n",
      "Epoch 105: loss = 0.001193 | Took : 49.9148 sec\n",
      "Validation Accuracy 0.9376\n",
      "Epoch 106: loss = 0.001206 | Took : 49.8637 sec\n",
      "Validation Accuracy 0.9386\n",
      "Epoch 107: loss = 0.001195 | Took : 49.8266 sec\n",
      "Validation Accuracy 0.9392\n",
      "Epoch 108: loss = 0.001210 | Took : 50.3029 sec\n",
      "Validation Accuracy 0.9416\n",
      "Epoch 109: loss = 0.001190 | Took : 49.9238 sec\n",
      "Validation Accuracy 0.9352\n",
      "Epoch 110: loss = 0.001171 | Took : 49.9048 sec\n",
      "Validation Accuracy 0.9384\n",
      "*** Test Accuracy 0.9358 ***\n",
      "Epoch 111: loss = 0.001198 | Took : 49.7584 sec\n",
      "Validation Accuracy 0.9396\n",
      "Epoch 112: loss = 0.001194 | Took : 49.8496 sec\n",
      "Validation Accuracy 0.9364\n",
      "Epoch 113: loss = 0.001177 | Took : 49.8105 sec\n",
      "Validation Accuracy 0.9344\n",
      "Epoch 114: loss = 0.001158 | Took : 50.4091 sec\n",
      "Validation Accuracy 0.9368\n",
      "Epoch 115: loss = 0.001179 | Took : 49.8196 sec\n",
      "Validation Accuracy 0.9388\n",
      "Epoch 116: loss = 0.001151 | Took : 49.8747 sec\n",
      "Validation Accuracy 0.9366\n",
      "Epoch 117: loss = 0.001158 | Took : 49.8436 sec\n",
      "Validation Accuracy 0.9434\n",
      "Epoch 118: loss = 0.001156 | Took : 49.8041 sec\n",
      "Validation Accuracy 0.9416\n",
      "Epoch 119: loss = 0.001159 | Took : 49.8065 sec\n",
      "Validation Accuracy 0.9342\n",
      "Epoch 120: loss = 0.001154 | Took : 50.4934 sec\n",
      "Validation Accuracy 0.9346\n",
      "*** Test Accuracy 0.9338 ***\n",
      "Epoch 121: loss = 0.001129 | Took : 49.8527 sec\n",
      "Validation Accuracy 0.9404\n",
      "Epoch 122: loss = 0.001127 | Took : 49.8386 sec\n",
      "Validation Accuracy 0.9360\n",
      "Epoch 123: loss = 0.001119 | Took : 49.8236 sec\n",
      "Validation Accuracy 0.9400\n",
      "Epoch 124: loss = 0.001139 | Took : 49.8857 sec\n",
      "Validation Accuracy 0.9404\n",
      "Epoch 125: loss = 0.001128 | Took : 49.8075 sec\n",
      "Validation Accuracy 0.9388\n",
      "Epoch 126: loss = 0.001124 | Took : 50.2236 sec\n",
      "Validation Accuracy 0.9392\n",
      "Epoch 127: loss = 0.001113 | Took : 49.6451 sec\n",
      "Validation Accuracy 0.9402\n",
      "Epoch 128: loss = 0.001107 | Took : 49.7865 sec\n",
      "Validation Accuracy 0.9406\n",
      "Epoch 129: loss = 0.001106 | Took : 49.8807 sec\n",
      "Validation Accuracy 0.9418\n",
      "Epoch 130: loss = 0.001076 | Took : 49.8125 sec\n",
      "Validation Accuracy 0.9420\n",
      "*** Test Accuracy 0.9358 ***\n",
      "Epoch 131: loss = 0.001089 | Took : 49.8396 sec\n",
      "Validation Accuracy 0.9410\n",
      "Epoch 132: loss = 0.001076 | Took : 50.0422 sec\n",
      "Validation Accuracy 0.9388\n",
      "Epoch 133: loss = 0.001071 | Took : 49.5729 sec\n",
      "Validation Accuracy 0.9420\n",
      "Epoch 134: loss = 0.001074 | Took : 49.8125 sec\n",
      "Validation Accuracy 0.9346\n",
      "Epoch 135: loss = 0.001054 | Took : 49.8888 sec\n",
      "Validation Accuracy 0.9352\n",
      "Epoch 136: loss = 0.001072 | Took : 49.8456 sec\n",
      "Validation Accuracy 0.9356\n",
      "Epoch 137: loss = 0.001062 | Took : 49.8557 sec\n",
      "Validation Accuracy 0.9404\n",
      "Epoch 138: loss = 0.001054 | Took : 49.9910 sec\n",
      "Validation Accuracy 0.9414\n",
      "Epoch 139: loss = 0.001068 | Took : 49.9830 sec\n",
      "Validation Accuracy 0.9400\n",
      "Epoch 140: loss = 0.001054 | Took : 49.8537 sec\n",
      "Validation Accuracy 0.9404\n",
      "*** Test Accuracy 0.9350 ***\n",
      "Epoch 141: loss = 0.001050 | Took : 49.8346 sec\n",
      "Validation Accuracy 0.9392\n",
      "Epoch 142: loss = 0.001045 | Took : 49.8456 sec\n",
      "Validation Accuracy 0.9478\n",
      "Epoch 143: loss = 0.001066 | Took : 49.8326 sec\n",
      "Validation Accuracy 0.9404\n",
      "Epoch 144: loss = 0.001020 | Took : 49.9459 sec\n",
      "Validation Accuracy 0.9374\n",
      "Epoch 145: loss = 0.001062 | Took : 49.9198 sec\n",
      "Validation Accuracy 0.9396\n",
      "Epoch 146: loss = 0.001018 | Took : 49.9730 sec\n",
      "Validation Accuracy 0.9396\n",
      "Epoch 147: loss = 0.001027 | Took : 53.3968 sec\n",
      "Validation Accuracy 0.9402\n",
      "Epoch 148: loss = 0.001012 | Took : 54.2309 sec\n",
      "Validation Accuracy 0.9380\n",
      "Epoch 149: loss = 0.001016 | Took : 54.1790 sec\n",
      "Validation Accuracy 0.9406\n",
      "Epoch 150: loss = 0.001018 | Took : 57.0867 sec\n",
      "Validation Accuracy 0.9408\n",
      "*** Test Accuracy 0.9379 ***\n",
      "--- Decrease learning rate to 1e-05 ---\n",
      "Epoch 151: loss = 0.000996 | Took : 54.1845 sec\n",
      "Validation Accuracy 0.9402\n",
      "Epoch 152: loss = 0.001016 | Took : 54.2724 sec\n",
      "Validation Accuracy 0.9380\n",
      "Epoch 153: loss = 0.001007 | Took : 54.5429 sec\n",
      "Validation Accuracy 0.9418\n",
      "Epoch 154: loss = 0.001000 | Took : 54.2536 sec\n",
      "Validation Accuracy 0.9370\n",
      "Epoch 155: loss = 0.000981 | Took : 54.3355 sec\n",
      "Validation Accuracy 0.9344\n",
      "Epoch 156: loss = 0.001001 | Took : 56.5932 sec\n",
      "Validation Accuracy 0.9410\n",
      "Epoch 157: loss = 0.000987 | Took : 54.3154 sec\n",
      "Validation Accuracy 0.9426\n",
      "Epoch 158: loss = 0.000992 | Took : 54.2216 sec\n",
      "Validation Accuracy 0.9388\n",
      "Epoch 159: loss = 0.000967 | Took : 54.4816 sec\n",
      "Validation Accuracy 0.9420\n",
      "Epoch 160: loss = 0.000983 | Took : 54.3380 sec\n",
      "Validation Accuracy 0.9428\n",
      "*** Test Accuracy 0.9387 ***\n",
      "Epoch 161: loss = 0.000965 | Took : 57.1786 sec\n",
      "Validation Accuracy 0.9422\n",
      "Epoch 162: loss = 0.000971 | Took : 54.7623 sec\n",
      "Validation Accuracy 0.9442\n",
      "Epoch 163: loss = 0.000956 | Took : 54.3796 sec\n",
      "Validation Accuracy 0.9448\n",
      "Epoch 164: loss = 0.000950 | Took : 54.5306 sec\n",
      "Validation Accuracy 0.9436\n",
      "Epoch 165: loss = 0.000965 | Took : 54.1911 sec\n",
      "Validation Accuracy 0.9446\n",
      "Epoch 166: loss = 0.000963 | Took : 54.3608 sec\n",
      "Validation Accuracy 0.9440\n",
      "Epoch 167: loss = 0.000972 | Took : 57.3404 sec\n",
      "Validation Accuracy 0.9442\n",
      "Epoch 168: loss = 0.000949 | Took : 55.2446 sec\n",
      "Validation Accuracy 0.9462\n",
      "Epoch 169: loss = 0.000954 | Took : 54.3178 sec\n",
      "Validation Accuracy 0.9446\n",
      "Epoch 170: loss = 0.000948 | Took : 54.6439 sec\n",
      "Validation Accuracy 0.9446\n",
      "*** Test Accuracy 0.9375 ***\n",
      "Epoch 171: loss = 0.000928 | Took : 54.0341 sec\n",
      "Validation Accuracy 0.9378\n",
      "Epoch 172: loss = 0.000942 | Took : 50.4622 sec\n",
      "Validation Accuracy 0.9446\n",
      "Epoch 173: loss = 0.000929 | Took : 49.9329 sec\n",
      "Validation Accuracy 0.9478\n",
      "Epoch 174: loss = 0.000923 | Took : 50.0361 sec\n",
      "Validation Accuracy 0.9426\n",
      "Epoch 175: loss = 0.000921 | Took : 50.0301 sec\n",
      "Validation Accuracy 0.9380\n",
      "Epoch 176: loss = 0.000916 | Took : 49.9629 sec\n",
      "Validation Accuracy 0.9452\n",
      "Epoch 177: loss = 0.000926 | Took : 50.0151 sec\n",
      "Validation Accuracy 0.9366\n",
      "Epoch 178: loss = 0.000890 | Took : 50.3309 sec\n",
      "Validation Accuracy 0.9430\n",
      "Epoch 179: loss = 0.000922 | Took : 49.8286 sec\n",
      "Validation Accuracy 0.9442\n",
      "Epoch 180: loss = 0.000915 | Took : 50.0512 sec\n",
      "Validation Accuracy 0.9440\n",
      "*** Test Accuracy 0.9384 ***\n",
      "Epoch 181: loss = 0.000921 | Took : 50.0472 sec\n",
      "Validation Accuracy 0.9412\n",
      "Epoch 182: loss = 0.000914 | Took : 49.9900 sec\n",
      "Validation Accuracy 0.9434\n",
      "Epoch 183: loss = 0.000904 | Took : 49.9890 sec\n",
      "Validation Accuracy 0.9424\n",
      "Epoch 184: loss = 0.000896 | Took : 50.1865 sec\n",
      "Validation Accuracy 0.9372\n",
      "Epoch 185: loss = 0.000883 | Took : 49.7153 sec\n",
      "Validation Accuracy 0.9432\n",
      "Epoch 186: loss = 0.000875 | Took : 50.0051 sec\n",
      "Validation Accuracy 0.9454\n",
      "Epoch 187: loss = 0.000896 | Took : 50.0151 sec\n",
      "Validation Accuracy 0.9456\n",
      "Epoch 188: loss = 0.000893 | Took : 50.0159 sec\n",
      "Validation Accuracy 0.9406\n",
      "Epoch 189: loss = 0.000879 | Took : 49.9898 sec\n",
      "Validation Accuracy 0.9364\n",
      "Epoch 190: loss = 0.000894 | Took : 50.0225 sec\n",
      "Validation Accuracy 0.9412\n",
      "*** Test Accuracy 0.9335 ***\n",
      "Epoch 191: loss = 0.000884 | Took : 49.8286 sec\n",
      "Validation Accuracy 0.9396\n",
      "Epoch 192: loss = 0.000864 | Took : 50.9554 sec\n",
      "Validation Accuracy 0.9420\n",
      "Epoch 193: loss = 0.000851 | Took : 50.0773 sec\n",
      "Validation Accuracy 0.9362\n",
      "Epoch 194: loss = 0.000898 | Took : 50.0492 sec\n",
      "Validation Accuracy 0.9424\n",
      "Epoch 195: loss = 0.000880 | Took : 50.0321 sec\n",
      "Validation Accuracy 0.9412\n",
      "Epoch 196: loss = 0.000862 | Took : 50.0321 sec\n",
      "Validation Accuracy 0.9426\n",
      "Epoch 197: loss = 0.000875 | Took : 50.0612 sec\n",
      "Validation Accuracy 0.9406\n",
      "Epoch 198: loss = 0.000859 | Took : 50.1620 sec\n",
      "Validation Accuracy 0.9416\n",
      "Epoch 199: loss = 0.000860 | Took : 50.0201 sec\n",
      "Validation Accuracy 0.9444\n",
      "Epoch 200: loss = 0.000850 | Took : 49.9559 sec\n",
      "Validation Accuracy 0.9392\n",
      "*** Test Accuracy 0.9365 ***\n"
     ]
    }
   ],
   "source": [
    "total_epochs = 200\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    ckpt = tf.train.get_checkpoint_state('./model')\n",
    "    # if ckpt and tf.train.checkpoint_exists(ckpt.model_checkpoint_path):\n",
    "    #     saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "    # else:\n",
    "    #     sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    writer = tf.summary.FileWriter('./graphs/fashion_mnist', sess.graph)\n",
    "    print('--- Start learning rate is {} ---'.format(lr))\n",
    "    step = gstep.eval()\n",
    "\n",
    "    for i in range(total_epochs):\n",
    "        if i == (total_epochs * 0.5) or i == (total_epochs * 0.75):\n",
    "            lr = lr / 10\n",
    "            print('--- Decrease learning rate to {} ---'.format(lr))\n",
    "        \n",
    "        start_time = time.time()\n",
    "        train_aug_data = lambda: train_data.map(augmentation).shuffle(50000).batch(batch_size)\n",
    "        sess.run(train_init)\n",
    "        is_training = True\n",
    "        total_loss, n_batches = 0, 0\n",
    "        try:\n",
    "            while True:\n",
    "                _, l, summary = sess.run([optimizer, loss, summary_op])\n",
    "                writer.add_summary(summary, global_step=step)\n",
    "                step += 1\n",
    "                n_batches += 1\n",
    "                total_loss += l\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            pass\n",
    "        \n",
    "        print('Epoch {0}: loss = {1:0.6f} | Took : {2:0.4f} sec'.format(\n",
    "              i+1, total_loss/n_samples, time.time() - start_time))\n",
    "        \n",
    "        is_training = False\n",
    "        sess.run(val_init)\n",
    "        total_correct_train = 0\n",
    "        try:\n",
    "            while True:\n",
    "                accuracy_train, summaries = sess.run([accuracy, summary_op])\n",
    "                writer.add_summary(summaries, global_step=step)\n",
    "                total_correct_train += accuracy_train\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            pass\n",
    "        \n",
    "        print('Validation Accuracy {0:0.4f}'.format(total_correct_train/5000))\n",
    "        \n",
    "        if (i+1) % 10 == 0:\n",
    "            # for calculate test accuracy\n",
    "            sess.run(test_init)\n",
    "            total_correct_preds = 0\n",
    "            try:\n",
    "                while True:\n",
    "                    accuracy_test, summaries = sess.run([accuracy, summary_op])\n",
    "                    writer.add_summary(summaries, global_step=step)\n",
    "                    total_correct_preds += accuracy_test\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                pass\n",
    "        \n",
    "            print('*** Test Accuracy {0:0.4f} ***'.format(total_correct_preds/n_test))\n",
    "    \n",
    "    writer.close()\n",
    "    saver.save(sess=sess, save_path='./model/fmnist_resnet_v1.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
