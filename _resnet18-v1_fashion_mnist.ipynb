{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion MNIST example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Make pipeline using Tensorflow Dataset API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./fashion_mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting ./fashion_mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./fashion_mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./fashion_mnist\\t10k-labels-idx1-ubyte.gz\n",
      "label =  2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnist_folder = './fashion_mnist'\n",
    "mnist = input_data.read_data_sets(mnist_folder, one_hot=True)\n",
    "\n",
    "train_data = tf.data.Dataset.from_tensor_slices((mnist.train.images, mnist.train.labels))\n",
    "val_data = tf.data.Dataset.from_tensor_slices((mnist.validation.images, mnist.validation.labels))\n",
    "test_data = tf.data.Dataset.from_tensor_slices((mnist.test.images, mnist.test.labels))\n",
    "\n",
    "index = 100\n",
    "print(\"label = \", np.argmax(mnist.train.labels[index]))\n",
    "plt.imshow(mnist.train.images[index].reshape(28, 28), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "n_samples = 55000\n",
    "n_test = 10000\n",
    "n_classes = 10\n",
    "batch_size = 64\n",
    "is_training = False\n",
    "_BATCH_NORM_DECAY = 0.997\n",
    "_BATCH_NORM_EPSILON = 1e-5\n",
    "\n",
    "gstep = tf.Variable(0, dtype=tf.int32, trainable=False, name='global_step')\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "_seed = tf.set_random_seed(1777)\n",
    "\n",
    "def augmentation(image, label):\n",
    "    with tf.name_scope('augmentation'):\n",
    "        image = tf.reshape(image, shape=[28, 28, 1])\n",
    "        image = tf.image.random_flip_left_right(image, seed=_seed) # random vertical flip\n",
    "        image = tf.image.random_flip_up_down(image, seed=_seed) # random horizeontal flip\n",
    "        \n",
    "        # random rotate an image counter-clockwise by 90 degrees.\n",
    "        rnd_rot90 = tf.cast(tf.random_uniform([], maxval=2, dtype=tf.int32, seed=_seed), tf.bool)\n",
    "        rnd_degree = tf.random_uniform([], maxval=3, dtype=tf.int32, seed=_seed)\n",
    "        image = tf.cond(rnd_rot90,\n",
    "                    lambda: tf.image.rot90(image, k=rnd_degree),\n",
    "                    lambda: tf.identity(image))\n",
    "        \n",
    "        # random crop\n",
    "        ori_image_shape = tf.shape(image)\n",
    "        rnd_crop = tf.random_uniform([], maxval=10, dtype=tf.int32, seed=_seed)\n",
    "        crop_size = 28 + rnd_crop\n",
    "        image = tf.image.resize_images(image, [crop_size, crop_size])\n",
    "        image = tf.random_crop(image, ori_image_shape, seed=_seed)\n",
    "        image = tf.reshape(image, shape=[784])\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Dataset'):\n",
    "    train_aug_data = train_data.map(augmentation).shuffle(55000).batch(batch_size)\n",
    "    val_data = val_data.batch(batch_size)\n",
    "    test_data = test_data.batch(batch_size)\n",
    "    \n",
    "    iterator = tf.data.Iterator.from_structure(train_aug_data.output_types,\n",
    "                                               train_aug_data.output_shapes)\n",
    "    x_image, y_label = iterator.get_next()\n",
    "\n",
    "    train_init = iterator.make_initializer(train_aug_data)\n",
    "    val_init = iterator.make_initializer(val_data)\n",
    "    test_init = iterator.make_initializer(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build model (refer to [tensorflow official resnet](https://github.com/tensorflow/models/blob/master/official/resnet/resnet_model.py) and [[2]](https://github.com/kefth/fashion-mnist/blob/master/model.py))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet v1\n",
    "def resnet_block(inputs, _filters, _strides=1, projection_shortcut=False):   \n",
    "    if projection_shortcut:\n",
    "        shortcut = tf.layers.conv2d(inputs, _filters, 1, _strides, 'valid', 'channels_first', use_bias=False,\n",
    "                                    kernel_initializer=tf.variance_scaling_initializer())\n",
    "        shortcut = tf.layers.batch_normalization(shortcut, 1, _BATCH_NORM_DECAY, _BATCH_NORM_EPSILON,\n",
    "                                                 training=is_training)\n",
    "        print('use projection shortcut')\n",
    "    else:\n",
    "        shortcut = tf.identity(inputs)\n",
    "    print('shortcut shape : {}'.format(np.shape(shortcut)))\n",
    "    \n",
    "    # if stride is not 1, add 'little' padding\n",
    "    if not _strides == 1:\n",
    "        out = tf.pad(inputs, [[0, 0], [0, 0], [1, 1], [1, 1]])\n",
    "        # [[0, 0], [0, 0], [1, 1], [1, 1]] pad will added\n",
    "        # channels_first data format : [batch, channels, height_in, width_in]\n",
    "    else:\n",
    "        out = tf.identity(inputs)\n",
    "    \n",
    "    out = tf.layers.conv2d(out, _filters, 3, _strides,\n",
    "                           'same' if _strides == 1 else 'valid', 'channels_first',\n",
    "                           use_bias=False, kernel_initializer=tf.variance_scaling_initializer())\n",
    "    out = tf.layers.batch_normalization(out, 1, _BATCH_NORM_DECAY, _BATCH_NORM_EPSILON,\n",
    "                                           training=is_training)\n",
    "    out = tf.nn.relu(out)\n",
    "    out = tf.layers.conv2d(out, _filters, 3, 1, 'same', 'channels_first',\n",
    "                           use_bias=False, kernel_initializer=tf.variance_scaling_initializer())\n",
    "    out = tf.layers.batch_normalization(out, 1, _BATCH_NORM_DECAY, _BATCH_NORM_EPSILON,\n",
    "                                        training=is_training)\n",
    "    out += shortcut\n",
    "    out = tf.nn.relu(out)\n",
    "    print('ResNet block output shape : {}'.format(np.shape(out)))\n",
    "    return out\n",
    "\n",
    "def avg_pooling(inputs):\n",
    "    shape = inputs.get_shape().as_list()\n",
    "    in_channel = [shape[2], shape[3]] # if not channels_first, then (shape[1], shape[2])\n",
    "    \n",
    "    out = tf.layers.batch_normalization(inputs, 1, _BATCH_NORM_DECAY, _BATCH_NORM_EPSILON,\n",
    "                                           training=is_training)\n",
    "    out = tf.nn.relu(out)\n",
    "    out = tf.layers.average_pooling2d(out, in_channel, 1, 'valid', 'channels_first')\n",
    "    \n",
    "    print('Average pooling output shape : {}'.format(np.shape(out)))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape : (?, 1, 28, 28)\n",
      "shortcut shape : (?, 64, 28, 28)\n",
      "ResNet block output shape : (?, 64, 28, 28)\n",
      "shortcut shape : (?, 64, 28, 28)\n",
      "ResNet block output shape : (?, 64, 28, 28)\n",
      "use projection shortcut\n",
      "shortcut shape : (?, 128, 14, 14)\n",
      "ResNet block output shape : (?, 128, 14, 14)\n",
      "shortcut shape : (?, 128, 14, 14)\n",
      "ResNet block output shape : (?, 128, 14, 14)\n",
      "use projection shortcut\n",
      "shortcut shape : (?, 256, 7, 7)\n",
      "ResNet block output shape : (?, 256, 7, 7)\n",
      "shortcut shape : (?, 256, 7, 7)\n",
      "ResNet block output shape : (?, 256, 7, 7)\n",
      "Average pooling output shape : (?, 256, 1, 1)\n",
      "after flatten output shape : (?, 256)\n"
     ]
    }
   ],
   "source": [
    "# Resnet 18-layer like model for fashion mnist\n",
    "image = tf.reshape(tensor=x_image, shape=[-1, 28, 28, 1])\n",
    "\n",
    "# for boost GPU processing | change data format to NCHW (Tensorflow defalut is NHWC)\n",
    "resnet = tf.transpose(image, [0, 3, 1, 2])\n",
    "print('input shape : {}'.format(np.shape(resnet)))\n",
    "\n",
    "resnet = tf.layers.conv2d(resnet, 64, 3, 1, 'same', 'channels_first', use_bias=False, \n",
    "                          kernel_initializer=tf.variance_scaling_initializer())\n",
    "resnet = tf.layers.batch_normalization(resnet, 1, _BATCH_NORM_DECAY, _BATCH_NORM_EPSILON,\n",
    "                                       training=is_training)\n",
    "resnet = tf.nn.relu(resnet)\n",
    "\n",
    "# 1st ResNet block \n",
    "resnet = resnet_block(resnet, 64)\n",
    "resnet = resnet_block(resnet, 64)\n",
    "# output shape [-1, 28, 28, 64]\n",
    "\n",
    "# 2nd ResNet block\n",
    "resnet = resnet_block(resnet, 128, 2, projection_shortcut=True)\n",
    "resnet = resnet_block(resnet, 128)\n",
    "# output shape [-1, 14, 14, 128]\n",
    "\n",
    "# 3rd ResNet block\n",
    "resnet = resnet_block(resnet, 256, 2, projection_shortcut=True)\n",
    "resnet = resnet_block(resnet, 256)\n",
    "# output shape [-1, 7, 7, 256]\n",
    "\n",
    "resnet = avg_pooling(resnet)\n",
    "# output shape [-1, 1, 1, 256]\n",
    "\n",
    "resnet = tf.layers.flatten(resnet)\n",
    "print('after flatten output shape : {}'.format(np.shape(resnet)))\n",
    "# output shape [-1, 256]\n",
    "logits = tf.layers.dense(resnet, n_classes, name='Logits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Loss Function / Optimizer / Prediction / Tensorboard summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('loss'):\n",
    "    entropy = tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_label, logits=logits)\n",
    "    loss = tf.reduce_mean(entropy, name='loss')\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(lr).minimize(loss)\n",
    "\n",
    "with tf.name_scope('predict'):\n",
    "    preds = tf.nn.softmax(logits)\n",
    "    correct_preds = tf.equal(tf.argmax(preds, 1), tf.argmax(y_label, 1))\n",
    "    accuracy = tf.reduce_sum(tf.cast(correct_preds, tf.float32))\n",
    "    \n",
    "with tf.name_scope('summaries'):\n",
    "    tf.summary.scalar('loss', loss)\n",
    "    tf.summary.scalar('accuracy', accuracy)\n",
    "    summary_op = tf.summary.merge_all()\n",
    "    \n",
    "saver = tf.train.Saver(tf.global_variables())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training & Test our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Start learning rate is 0.001 ---\n",
      "Epoch 1: loss = 0.016737 | Took : 59.9717 sec\n",
      "Validation Accuracy 0.7940\n",
      "Epoch 2: loss = 0.009964 | Took : 66.3089 sec\n",
      "Validation Accuracy 0.8434\n",
      "Epoch 3: loss = 0.008468 | Took : 60.2064 sec\n",
      "Validation Accuracy 0.8634\n",
      "Epoch 4: loss = 0.007565 | Took : 57.4034 sec\n",
      "Validation Accuracy 0.8550\n",
      "Epoch 5: loss = 0.006961 | Took : 57.4096 sec\n",
      "Validation Accuracy 0.8746\n",
      "Epoch 6: loss = 0.006586 | Took : 57.1890 sec\n",
      "Validation Accuracy 0.8896\n",
      "Epoch 7: loss = 0.006289 | Took : 68.3976 sec\n",
      "Validation Accuracy 0.8974\n",
      "Epoch 8: loss = 0.006056 | Took : 58.4845 sec\n",
      "Validation Accuracy 0.8992\n",
      "Epoch 9: loss = 0.005793 | Took : 57.6455 sec\n",
      "Validation Accuracy 0.8974\n",
      "Epoch 10: loss = 0.005665 | Took : 57.4713 sec\n",
      "Validation Accuracy 0.8970\n",
      "*** Test Accuracy 0.8874 ***\n",
      "Epoch 11: loss = 0.005513 | Took : 57.8870 sec\n",
      "Validation Accuracy 0.9036\n",
      "Epoch 12: loss = 0.005333 | Took : 66.3924 sec\n",
      "Validation Accuracy 0.9090\n",
      "Epoch 13: loss = 0.005228 | Took : 57.6411 sec\n",
      "Validation Accuracy 0.9054\n",
      "Epoch 14: loss = 0.005127 | Took : 57.8294 sec\n",
      "Validation Accuracy 0.9098\n",
      "Epoch 15: loss = 0.005057 | Took : 57.5693 sec\n",
      "Validation Accuracy 0.9090\n",
      "Epoch 16: loss = 0.005015 | Took : 57.3935 sec\n",
      "Validation Accuracy 0.9068\n",
      "Epoch 17: loss = 0.004881 | Took : 66.2200 sec\n",
      "Validation Accuracy 0.9040\n",
      "Epoch 18: loss = 0.004774 | Took : 57.6774 sec\n",
      "Validation Accuracy 0.9090\n",
      "Epoch 19: loss = 0.004760 | Took : 58.0299 sec\n",
      "Validation Accuracy 0.9190\n",
      "Epoch 20: loss = 0.004682 | Took : 57.5218 sec\n",
      "Validation Accuracy 0.9194\n",
      "*** Test Accuracy 0.9078 ***\n",
      "Epoch 21: loss = 0.004539 | Took : 57.6581 sec\n",
      "Validation Accuracy 0.9112\n",
      "Epoch 22: loss = 0.004508 | Took : 66.2495 sec\n",
      "Validation Accuracy 0.9128\n",
      "Epoch 23: loss = 0.004499 | Took : 57.5968 sec\n",
      "Validation Accuracy 0.9186\n",
      "Epoch 24: loss = 0.004418 | Took : 57.6021 sec\n",
      "Validation Accuracy 0.9190\n",
      "Epoch 25: loss = 0.004403 | Took : 57.6426 sec\n",
      "Validation Accuracy 0.9110\n",
      "Epoch 26: loss = 0.004280 | Took : 57.7216 sec\n",
      "Validation Accuracy 0.9226\n",
      "Epoch 27: loss = 0.004329 | Took : 57.7887 sec\n",
      "Validation Accuracy 0.9196\n",
      "Epoch 28: loss = 0.004288 | Took : 62.1384 sec\n",
      "Validation Accuracy 0.9220\n",
      "Epoch 29: loss = 0.004184 | Took : 57.9998 sec\n",
      "Validation Accuracy 0.9186\n",
      "Epoch 30: loss = 0.004145 | Took : 57.5676 sec\n",
      "Validation Accuracy 0.9232\n",
      "*** Test Accuracy 0.9148 ***\n",
      "Epoch 31: loss = 0.004094 | Took : 57.7989 sec\n",
      "Validation Accuracy 0.9258\n",
      "Epoch 32: loss = 0.004135 | Took : 57.7252 sec\n",
      "Validation Accuracy 0.9180\n",
      "Epoch 33: loss = 0.004018 | Took : 66.0097 sec\n",
      "Validation Accuracy 0.9236\n",
      "Epoch 34: loss = 0.003995 | Took : 57.6534 sec\n",
      "Validation Accuracy 0.9252\n",
      "Epoch 35: loss = 0.003927 | Took : 57.5138 sec\n",
      "Validation Accuracy 0.9262\n",
      "Epoch 36: loss = 0.003949 | Took : 59.8401 sec\n",
      "Validation Accuracy 0.9230\n",
      "Epoch 37: loss = 0.003916 | Took : 57.3034 sec\n",
      "Validation Accuracy 0.9232\n",
      "Epoch 38: loss = 0.003873 | Took : 65.8779 sec\n",
      "Validation Accuracy 0.9286\n",
      "Epoch 39: loss = 0.003825 | Took : 57.5184 sec\n",
      "Validation Accuracy 0.9288\n",
      "Epoch 40: loss = 0.003780 | Took : 57.5311 sec\n",
      "Validation Accuracy 0.9282\n",
      "*** Test Accuracy 0.9188 ***\n",
      "Epoch 41: loss = 0.003771 | Took : 57.4892 sec\n",
      "Validation Accuracy 0.9272\n",
      "Epoch 42: loss = 0.003717 | Took : 57.4246 sec\n",
      "Validation Accuracy 0.9192\n",
      "Epoch 43: loss = 0.003741 | Took : 66.0735 sec\n",
      "Validation Accuracy 0.9234\n",
      "Epoch 44: loss = 0.003703 | Took : 57.5518 sec\n",
      "Validation Accuracy 0.9274\n",
      "Epoch 45: loss = 0.003681 | Took : 57.7129 sec\n",
      "Validation Accuracy 0.9222\n",
      "Epoch 46: loss = 0.003628 | Took : 57.4197 sec\n",
      "Validation Accuracy 0.9272\n",
      "Epoch 47: loss = 0.003659 | Took : 57.6092 sec\n",
      "Validation Accuracy 0.9260\n",
      "Epoch 48: loss = 0.003638 | Took : 66.0128 sec\n",
      "Validation Accuracy 0.9292\n",
      "Epoch 49: loss = 0.003575 | Took : 57.7240 sec\n",
      "Validation Accuracy 0.9256\n",
      "Epoch 50: loss = 0.003555 | Took : 57.4818 sec\n",
      "Validation Accuracy 0.9340\n",
      "*** Test Accuracy 0.9252 ***\n",
      "Epoch 51: loss = 0.003525 | Took : 57.7208 sec\n",
      "Validation Accuracy 0.9324\n",
      "Epoch 52: loss = 0.003501 | Took : 57.6042 sec\n",
      "Validation Accuracy 0.9318\n",
      "Epoch 53: loss = 0.003492 | Took : 66.1379 sec\n",
      "Validation Accuracy 0.9310\n",
      "Epoch 54: loss = 0.003525 | Took : 57.5909 sec\n",
      "Validation Accuracy 0.9308\n",
      "Epoch 55: loss = 0.003428 | Took : 57.6564 sec\n",
      "Validation Accuracy 0.9256\n",
      "Epoch 56: loss = 0.003390 | Took : 57.6533 sec\n",
      "Validation Accuracy 0.9292\n",
      "Epoch 57: loss = 0.003413 | Took : 59.3423 sec\n",
      "Validation Accuracy 0.9316\n",
      "Epoch 58: loss = 0.003349 | Took : 66.2096 sec\n",
      "Validation Accuracy 0.9312\n",
      "Epoch 59: loss = 0.003369 | Took : 57.7539 sec\n",
      "Validation Accuracy 0.9276\n",
      "Epoch 60: loss = 0.003357 | Took : 57.6472 sec\n",
      "Validation Accuracy 0.9310\n",
      "*** Test Accuracy 0.9275 ***\n",
      "Epoch 61: loss = 0.003351 | Took : 57.6651 sec\n",
      "Validation Accuracy 0.9356\n",
      "Epoch 62: loss = 0.003306 | Took : 57.4459 sec\n",
      "Validation Accuracy 0.9316\n",
      "Epoch 63: loss = 0.003289 | Took : 65.6987 sec\n",
      "Validation Accuracy 0.9292\n",
      "Epoch 64: loss = 0.003258 | Took : 57.5397 sec\n",
      "Validation Accuracy 0.9340\n",
      "Epoch 65: loss = 0.003264 | Took : 57.5270 sec\n",
      "Validation Accuracy 0.9306\n",
      "Epoch 66: loss = 0.003246 | Took : 57.5326 sec\n",
      "Validation Accuracy 0.9334\n",
      "Epoch 67: loss = 0.003183 | Took : 57.5824 sec\n",
      "Validation Accuracy 0.9326\n",
      "Epoch 68: loss = 0.003200 | Took : 66.0069 sec\n",
      "Validation Accuracy 0.9302\n",
      "Epoch 69: loss = 0.003217 | Took : 58.0115 sec\n",
      "Validation Accuracy 0.9312\n",
      "Epoch 70: loss = 0.003161 | Took : 57.8349 sec\n",
      "Validation Accuracy 0.9412\n",
      "*** Test Accuracy 0.9277 ***\n",
      "Epoch 71: loss = 0.003143 | Took : 57.8828 sec\n",
      "Validation Accuracy 0.9334\n",
      "Epoch 72: loss = 0.003168 | Took : 57.5431 sec\n",
      "Validation Accuracy 0.9276\n",
      "Epoch 73: loss = 0.003113 | Took : 66.4618 sec\n",
      "Validation Accuracy 0.9362\n",
      "Epoch 74: loss = 0.003095 | Took : 57.9200 sec\n",
      "Validation Accuracy 0.9322\n",
      "Epoch 75: loss = 0.003093 | Took : 57.4667 sec\n",
      "Validation Accuracy 0.9320\n",
      "Epoch 76: loss = 0.003061 | Took : 57.5104 sec\n",
      "Validation Accuracy 0.9318\n",
      "Epoch 77: loss = 0.003036 | Took : 57.6072 sec\n",
      "Validation Accuracy 0.9362\n",
      "Epoch 78: loss = 0.003046 | Took : 57.9540 sec\n",
      "Validation Accuracy 0.9326\n",
      "Epoch 79: loss = 0.003030 | Took : 64.5516 sec\n",
      "Validation Accuracy 0.9310\n",
      "Epoch 80: loss = 0.003008 | Took : 57.7401 sec\n",
      "Validation Accuracy 0.9296\n",
      "*** Test Accuracy 0.9242 ***\n",
      "Epoch 81: loss = 0.002983 | Took : 57.6516 sec\n",
      "Validation Accuracy 0.9308\n",
      "Epoch 82: loss = 0.002986 | Took : 57.4862 sec\n",
      "Validation Accuracy 0.9332\n",
      "Epoch 83: loss = 0.002918 | Took : 57.4860 sec\n",
      "Validation Accuracy 0.9330\n",
      "Epoch 84: loss = 0.003004 | Took : 67.1949 sec\n",
      "Validation Accuracy 0.9326\n",
      "Epoch 85: loss = 0.002945 | Took : 57.8260 sec\n",
      "Validation Accuracy 0.9364\n",
      "Epoch 86: loss = 0.002945 | Took : 57.4219 sec\n",
      "Validation Accuracy 0.9350\n",
      "Epoch 87: loss = 0.002908 | Took : 57.6211 sec\n",
      "Validation Accuracy 0.9390\n",
      "Epoch 88: loss = 0.002880 | Took : 57.6057 sec\n",
      "Validation Accuracy 0.9320\n",
      "Epoch 89: loss = 0.002895 | Took : 66.0630 sec\n",
      "Validation Accuracy 0.9328\n",
      "Epoch 90: loss = 0.002805 | Took : 57.7904 sec\n",
      "Validation Accuracy 0.9334\n",
      "*** Test Accuracy 0.9318 ***\n",
      "Epoch 91: loss = 0.002883 | Took : 57.5583 sec\n",
      "Validation Accuracy 0.9354\n",
      "Epoch 92: loss = 0.002855 | Took : 57.2982 sec\n",
      "Validation Accuracy 0.9348\n",
      "Epoch 93: loss = 0.002868 | Took : 57.7209 sec\n",
      "Validation Accuracy 0.9398\n",
      "Epoch 94: loss = 0.002821 | Took : 65.7273 sec\n",
      "Validation Accuracy 0.9382\n",
      "Epoch 95: loss = 0.002816 | Took : 57.4927 sec\n",
      "Validation Accuracy 0.9394\n",
      "Epoch 96: loss = 0.002765 | Took : 57.5896 sec\n",
      "Validation Accuracy 0.9342\n",
      "Epoch 97: loss = 0.002811 | Took : 57.3812 sec\n",
      "Validation Accuracy 0.9356\n",
      "Epoch 98: loss = 0.002747 | Took : 57.9165 sec\n",
      "Validation Accuracy 0.9326\n",
      "Epoch 99: loss = 0.002744 | Took : 66.0764 sec\n",
      "Validation Accuracy 0.9334\n",
      "Epoch 100: loss = 0.002791 | Took : 57.7521 sec\n",
      "Validation Accuracy 0.9330\n",
      "*** Test Accuracy 0.9296 ***\n",
      "--- Decrease learning rate to 0.0001 ---\n",
      "Epoch 101: loss = 0.002736 | Took : 57.7485 sec\n",
      "Validation Accuracy 0.9350\n",
      "Epoch 102: loss = 0.002759 | Took : 57.5799 sec\n",
      "Validation Accuracy 0.9332\n",
      "Epoch 103: loss = 0.002733 | Took : 57.8701 sec\n",
      "Validation Accuracy 0.9338\n",
      "Epoch 104: loss = 0.002701 | Took : 66.1513 sec\n",
      "Validation Accuracy 0.9408\n",
      "Epoch 105: loss = 0.002666 | Took : 58.4105 sec\n",
      "Validation Accuracy 0.9354\n",
      "Epoch 106: loss = 0.002683 | Took : 57.3356 sec\n",
      "Validation Accuracy 0.9362\n",
      "Epoch 107: loss = 0.002684 | Took : 57.5902 sec\n",
      "Validation Accuracy 0.9410\n",
      "Epoch 108: loss = 0.002665 | Took : 57.2482 sec\n",
      "Validation Accuracy 0.9330\n",
      "Epoch 109: loss = 0.002622 | Took : 65.5487 sec\n",
      "Validation Accuracy 0.9380\n",
      "Epoch 110: loss = 0.002639 | Took : 57.7055 sec\n",
      "Validation Accuracy 0.9392\n",
      "*** Test Accuracy 0.9349 ***\n",
      "Epoch 111: loss = 0.002595 | Took : 57.5789 sec\n",
      "Validation Accuracy 0.9322\n",
      "Epoch 112: loss = 0.002595 | Took : 57.3354 sec\n",
      "Validation Accuracy 0.9356\n",
      "Epoch 113: loss = 0.002617 | Took : 57.5692 sec\n",
      "Validation Accuracy 0.9322\n",
      "Epoch 114: loss = 0.002584 | Took : 65.7861 sec\n",
      "Validation Accuracy 0.9390\n",
      "Epoch 115: loss = 0.002562 | Took : 57.7095 sec\n",
      "Validation Accuracy 0.9370\n",
      "Epoch 116: loss = 0.002571 | Took : 57.9986 sec\n",
      "Validation Accuracy 0.9384\n",
      "Epoch 117: loss = 0.002524 | Took : 57.8156 sec\n",
      "Validation Accuracy 0.9364\n",
      "Epoch 118: loss = 0.002556 | Took : 57.5935 sec\n",
      "Validation Accuracy 0.9340\n",
      "Epoch 119: loss = 0.002538 | Took : 69.0357 sec\n",
      "Validation Accuracy 0.9330\n",
      "Epoch 120: loss = 0.002546 | Took : 57.9583 sec\n",
      "Validation Accuracy 0.9320\n",
      "*** Test Accuracy 0.9283 ***\n",
      "Epoch 121: loss = 0.002500 | Took : 57.6281 sec\n",
      "Validation Accuracy 0.9340\n",
      "Epoch 122: loss = 0.002508 | Took : 57.5513 sec\n",
      "Validation Accuracy 0.9320\n",
      "Epoch 123: loss = 0.002525 | Took : 57.5650 sec\n",
      "Validation Accuracy 0.9436\n",
      "Epoch 124: loss = 0.002524 | Took : 65.8713 sec\n",
      "Validation Accuracy 0.9354\n",
      "Epoch 125: loss = 0.002493 | Took : 57.4801 sec\n",
      "Validation Accuracy 0.9418\n",
      "Epoch 126: loss = 0.002488 | Took : 57.6230 sec\n",
      "Validation Accuracy 0.9364\n",
      "Epoch 127: loss = 0.002471 | Took : 57.7832 sec\n",
      "Validation Accuracy 0.9394\n",
      "Epoch 128: loss = 0.002474 | Took : 57.5986 sec\n",
      "Validation Accuracy 0.9398\n",
      "Epoch 129: loss = 0.002484 | Took : 57.4796 sec\n",
      "Validation Accuracy 0.9350\n",
      "Epoch 130: loss = 0.002432 | Took : 64.9067 sec\n",
      "Validation Accuracy 0.9368\n",
      "*** Test Accuracy 0.9324 ***\n",
      "Epoch 131: loss = 0.002473 | Took : 57.4183 sec\n",
      "Validation Accuracy 0.9392\n",
      "Epoch 132: loss = 0.002434 | Took : 57.3378 sec\n",
      "Validation Accuracy 0.9398\n",
      "Epoch 133: loss = 0.002412 | Took : 57.4613 sec\n",
      "Validation Accuracy 0.9392\n",
      "Epoch 134: loss = 0.002433 | Took : 57.5315 sec\n",
      "Validation Accuracy 0.9344\n",
      "Epoch 135: loss = 0.002394 | Took : 65.5927 sec\n",
      "Validation Accuracy 0.9346\n",
      "Epoch 136: loss = 0.002437 | Took : 57.3259 sec\n",
      "Validation Accuracy 0.9378\n",
      "Epoch 137: loss = 0.002396 | Took : 60.8873 sec\n",
      "Validation Accuracy 0.9352\n",
      "Epoch 138: loss = 0.002389 | Took : 63.5934 sec\n",
      "Validation Accuracy 0.9402\n",
      "Epoch 139: loss = 0.002342 | Took : 57.5299 sec\n",
      "Validation Accuracy 0.9408\n",
      "Epoch 140: loss = 0.002375 | Took : 66.7455 sec\n",
      "Validation Accuracy 0.9390\n",
      "*** Test Accuracy 0.9289 ***\n",
      "Epoch 141: loss = 0.002355 | Took : 57.4986 sec\n",
      "Validation Accuracy 0.9360\n",
      "Epoch 142: loss = 0.002344 | Took : 57.6445 sec\n",
      "Validation Accuracy 0.9386\n",
      "Epoch 143: loss = 0.002312 | Took : 57.3667 sec\n",
      "Validation Accuracy 0.9366\n",
      "Epoch 144: loss = 0.002353 | Took : 57.7015 sec\n",
      "Validation Accuracy 0.9418\n",
      "Epoch 145: loss = 0.002297 | Took : 65.8594 sec\n",
      "Validation Accuracy 0.9428\n",
      "Epoch 146: loss = 0.002304 | Took : 57.9274 sec\n",
      "Validation Accuracy 0.9348\n",
      "Epoch 147: loss = 0.002279 | Took : 57.3923 sec\n",
      "Validation Accuracy 0.9376\n",
      "Epoch 148: loss = 0.002303 | Took : 57.4101 sec\n",
      "Validation Accuracy 0.9376\n",
      "Epoch 149: loss = 0.002265 | Took : 57.6351 sec\n",
      "Validation Accuracy 0.9382\n",
      "Epoch 150: loss = 0.002321 | Took : 65.7529 sec\n",
      "Validation Accuracy 0.9420\n",
      "*** Test Accuracy 0.9370 ***\n",
      "--- Decrease learning rate to 1e-05 ---\n",
      "Epoch 151: loss = 0.002296 | Took : 57.6250 sec\n",
      "Validation Accuracy 0.9406\n",
      "Epoch 152: loss = 0.002268 | Took : 57.4184 sec\n",
      "Validation Accuracy 0.9300\n",
      "Epoch 153: loss = 0.002274 | Took : 57.3539 sec\n",
      "Validation Accuracy 0.9348\n",
      "Epoch 154: loss = 0.002269 | Took : 62.6688 sec\n",
      "Validation Accuracy 0.9360\n",
      "Epoch 155: loss = 0.002242 | Took : 65.6255 sec\n",
      "Validation Accuracy 0.9322\n",
      "Epoch 156: loss = 0.002254 | Took : 57.5138 sec\n",
      "Validation Accuracy 0.9332\n",
      "Epoch 157: loss = 0.002252 | Took : 57.4968 sec\n",
      "Validation Accuracy 0.9386\n",
      "Epoch 158: loss = 0.002219 | Took : 57.2945 sec\n",
      "Validation Accuracy 0.9360\n",
      "Epoch 159: loss = 0.002217 | Took : 57.6178 sec\n",
      "Validation Accuracy 0.9372\n",
      "Epoch 160: loss = 0.002214 | Took : 65.6601 sec\n",
      "Validation Accuracy 0.9338\n",
      "*** Test Accuracy 0.9330 ***\n",
      "Epoch 161: loss = 0.002221 | Took : 57.6094 sec\n",
      "Validation Accuracy 0.9382\n",
      "Epoch 162: loss = 0.002146 | Took : 57.6071 sec\n",
      "Validation Accuracy 0.9364\n",
      "Epoch 163: loss = 0.002193 | Took : 57.6512 sec\n",
      "Validation Accuracy 0.9384\n",
      "Epoch 164: loss = 0.002192 | Took : 57.6561 sec\n",
      "Validation Accuracy 0.9370\n",
      "Epoch 165: loss = 0.002142 | Took : 65.8064 sec\n",
      "Validation Accuracy 0.9414\n",
      "Epoch 166: loss = 0.002192 | Took : 57.7315 sec\n",
      "Validation Accuracy 0.9352\n",
      "Epoch 167: loss = 0.002181 | Took : 57.9726 sec\n",
      "Validation Accuracy 0.9362\n",
      "Epoch 168: loss = 0.002135 | Took : 57.7365 sec\n",
      "Validation Accuracy 0.9390\n",
      "Epoch 169: loss = 0.002176 | Took : 57.6843 sec\n",
      "Validation Accuracy 0.9368\n",
      "Epoch 170: loss = 0.002193 | Took : 65.6402 sec\n",
      "Validation Accuracy 0.9372\n",
      "*** Test Accuracy 0.9342 ***\n",
      "Epoch 171: loss = 0.002105 | Took : 57.7185 sec\n",
      "Validation Accuracy 0.9372\n",
      "Epoch 172: loss = 0.002121 | Took : 57.5267 sec\n",
      "Validation Accuracy 0.9364\n",
      "Epoch 173: loss = 0.002133 | Took : 57.5533 sec\n",
      "Validation Accuracy 0.9398\n",
      "Epoch 174: loss = 0.002137 | Took : 57.5909 sec\n",
      "Validation Accuracy 0.9376\n",
      "Epoch 175: loss = 0.002116 | Took : 66.2195 sec\n",
      "Validation Accuracy 0.9388\n",
      "Epoch 176: loss = 0.002056 | Took : 57.9748 sec\n",
      "Validation Accuracy 0.9400\n",
      "Epoch 177: loss = 0.002057 | Took : 58.2708 sec\n",
      "Validation Accuracy 0.9350\n",
      "Epoch 178: loss = 0.002107 | Took : 57.5968 sec\n",
      "Validation Accuracy 0.9330\n",
      "Epoch 179: loss = 0.002094 | Took : 57.3279 sec\n",
      "Validation Accuracy 0.9380\n",
      "Epoch 180: loss = 0.002083 | Took : 66.2710 sec\n",
      "Validation Accuracy 0.9384\n",
      "*** Test Accuracy 0.9381 ***\n",
      "Epoch 181: loss = 0.002055 | Took : 57.3625 sec\n",
      "Validation Accuracy 0.9400\n",
      "Epoch 182: loss = 0.002079 | Took : 57.3944 sec\n",
      "Validation Accuracy 0.9366\n",
      "Epoch 183: loss = 0.002050 | Took : 57.2381 sec\n",
      "Validation Accuracy 0.9342\n",
      "Epoch 184: loss = 0.002062 | Took : 57.7724 sec\n",
      "Validation Accuracy 0.9338\n",
      "Epoch 185: loss = 0.002020 | Took : 57.9284 sec\n",
      "Validation Accuracy 0.9332\n",
      "Epoch 186: loss = 0.002033 | Took : 62.2655 sec\n",
      "Validation Accuracy 0.9400\n",
      "Epoch 187: loss = 0.002085 | Took : 57.2610 sec\n",
      "Validation Accuracy 0.9384\n",
      "Epoch 188: loss = 0.002013 | Took : 57.5119 sec\n",
      "Validation Accuracy 0.9358\n",
      "Epoch 189: loss = 0.002035 | Took : 57.4390 sec\n",
      "Validation Accuracy 0.9392\n",
      "Epoch 190: loss = 0.002031 | Took : 61.1312 sec\n",
      "Validation Accuracy 0.9390\n",
      "*** Test Accuracy 0.9380 ***\n",
      "Epoch 191: loss = 0.002038 | Took : 65.7296 sec\n",
      "Validation Accuracy 0.9380\n",
      "Epoch 192: loss = 0.001955 | Took : 57.3582 sec\n",
      "Validation Accuracy 0.9390\n",
      "Epoch 193: loss = 0.001994 | Took : 57.6996 sec\n",
      "Validation Accuracy 0.9384\n",
      "Epoch 194: loss = 0.001997 | Took : 57.5990 sec\n",
      "Validation Accuracy 0.9338\n",
      "Epoch 195: loss = 0.001985 | Took : 57.4782 sec\n",
      "Validation Accuracy 0.9418\n",
      "Epoch 196: loss = 0.001989 | Took : 65.9888 sec\n",
      "Validation Accuracy 0.9384\n",
      "Epoch 197: loss = 0.002012 | Took : 56.9207 sec\n",
      "Validation Accuracy 0.9368\n",
      "Epoch 198: loss = 0.001987 | Took : 57.2300 sec\n",
      "Validation Accuracy 0.9390\n",
      "Epoch 199: loss = 0.001949 | Took : 57.6274 sec\n",
      "Validation Accuracy 0.9408\n",
      "Epoch 200: loss = 0.001929 | Took : 57.6357 sec\n",
      "Validation Accuracy 0.9360\n",
      "*** Test Accuracy 0.9349 ***\n"
     ]
    }
   ],
   "source": [
    "total_epochs = 200\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    ckpt = tf.train.get_checkpoint_state('./model')\n",
    "    # if ckpt and tf.train.checkpoint_exists(ckpt.model_checkpoint_path):\n",
    "    #     saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "    # else:\n",
    "    #     sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    writer = tf.summary.FileWriter('./graphs/fashion_mnist', sess.graph)\n",
    "    print('--- Start learning rate is {} ---'.format(lr))\n",
    "    step = gstep.eval()\n",
    "\n",
    "    for i in range(total_epochs):\n",
    "        if i == (total_epochs * 0.5) or i == (total_epochs * 0.75):\n",
    "            lr = lr / 10\n",
    "            print('--- Decrease learning rate to {} ---'.format(lr))\n",
    "        \n",
    "        start_time = time.time()\n",
    "        train_aug_data = lambda: train_data.map(augmentation).shuffle(50000).batch(batch_size)\n",
    "        sess.run(train_init)\n",
    "        is_training = True\n",
    "        total_loss, n_batches = 0, 0\n",
    "        try:\n",
    "            while True:\n",
    "                _, l, summary = sess.run([optimizer, loss, summary_op])\n",
    "                writer.add_summary(summary, global_step=step)\n",
    "                step += 1\n",
    "                n_batches += 1\n",
    "                total_loss += l\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            pass\n",
    "        \n",
    "        print('Epoch {0}: loss = {1:0.6f} | Took : {2:0.4f} sec'.format(\n",
    "              i+1, total_loss/n_samples, time.time() - start_time))\n",
    "        \n",
    "        is_training = False\n",
    "        sess.run(val_init)\n",
    "        total_correct_train = 0\n",
    "        try:\n",
    "            while True:\n",
    "                accuracy_train, summaries = sess.run([accuracy, summary_op])\n",
    "                writer.add_summary(summaries, global_step=step)\n",
    "                total_correct_train += accuracy_train\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            pass\n",
    "        \n",
    "        print('Validation Accuracy {0:0.4f}'.format(total_correct_train/5000))\n",
    "        \n",
    "        if (i+1) % 10 == 0:\n",
    "            # for calculate test accuracy\n",
    "            sess.run(test_init)\n",
    "            total_correct_preds = 0\n",
    "            try:\n",
    "                while True:\n",
    "                    accuracy_test, summaries = sess.run([accuracy, summary_op])\n",
    "                    writer.add_summary(summaries, global_step=step)\n",
    "                    total_correct_preds += accuracy_test\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                pass\n",
    "        \n",
    "            print('*** Test Accuracy {0:0.4f} ***'.format(total_correct_preds/n_test))\n",
    "    \n",
    "    writer.close()\n",
    "    saver.save(sess=sess, save_path='./model/fmnist_resnet.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
