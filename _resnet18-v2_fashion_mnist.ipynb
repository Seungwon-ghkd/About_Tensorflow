{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion MNIST example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Make pipeline using Tensorflow Dataset API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./fashion_mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting ./fashion_mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./fashion_mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./fashion_mnist\\t10k-labels-idx1-ubyte.gz\n",
      "label =  2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnist_folder = './fashion_mnist'\n",
    "mnist = input_data.read_data_sets(mnist_folder, one_hot=True)\n",
    "\n",
    "train_data = tf.data.Dataset.from_tensor_slices((mnist.train.images, mnist.train.labels))\n",
    "val_data = tf.data.Dataset.from_tensor_slices((mnist.validation.images, mnist.validation.labels))\n",
    "test_data = tf.data.Dataset.from_tensor_slices((mnist.test.images, mnist.test.labels))\n",
    "\n",
    "index = 100\n",
    "print(\"label = \", np.argmax(mnist.train.labels[index]))\n",
    "plt.imshow(mnist.train.images[index].reshape(28, 28), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "n_samples = 55000\n",
    "n_test = 10000\n",
    "n_classes = 10\n",
    "batch_size = 128\n",
    "is_training = False\n",
    "_BATCH_NORM_DECAY = 0.997\n",
    "_BATCH_NORM_EPSILON = 1e-5\n",
    "\n",
    "gstep = tf.Variable(0, dtype=tf.int32, trainable=False, name='global_step')\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "_seed = tf.set_random_seed(1777)\n",
    "\n",
    "def augmentation(image, label):\n",
    "    with tf.name_scope('augmentation'):\n",
    "        image = tf.reshape(image, shape=[28, 28, 1])\n",
    "        image = tf.image.random_flip_left_right(image, seed=_seed) # random vertical flip\n",
    "        image = tf.image.random_flip_up_down(image, seed=_seed) # random horizeontal flip\n",
    "        \n",
    "        # random rotate an image counter-clockwise by 90 degrees.\n",
    "        rnd_rot90 = tf.cast(tf.random_uniform([], maxval=2, dtype=tf.int32, seed=_seed), tf.bool)\n",
    "        rnd_degree = tf.random_uniform([], maxval=3, dtype=tf.int32, seed=_seed)\n",
    "        image = tf.cond(rnd_rot90,\n",
    "                    lambda: tf.image.rot90(image, k=rnd_degree),\n",
    "                    lambda: tf.identity(image))\n",
    "        \n",
    "        # random crop\n",
    "        ori_image_shape = tf.shape(image)\n",
    "        rnd_crop = tf.random_uniform([], maxval=10, dtype=tf.int32, seed=_seed)\n",
    "        crop_size = 28 + rnd_crop\n",
    "        image = tf.image.resize_images(image, [crop_size, crop_size])\n",
    "        image = tf.random_crop(image, ori_image_shape, seed=_seed)\n",
    "        image = tf.reshape(image, shape=[784])\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Dataset'):\n",
    "    train_aug_data = train_data.map(augmentation).shuffle(55000).batch(batch_size)\n",
    "    val_data = val_data.batch(batch_size)\n",
    "    test_data = test_data.batch(batch_size)\n",
    "    \n",
    "    iterator = tf.data.Iterator.from_structure(train_aug_data.output_types,\n",
    "                                               train_aug_data.output_shapes)\n",
    "    x_image, y_label = iterator.get_next()\n",
    "\n",
    "    train_init = iterator.make_initializer(train_aug_data)\n",
    "    val_init = iterator.make_initializer(val_data)\n",
    "    test_init = iterator.make_initializer(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build model (refer to [tensorflow official resnet](https://github.com/tensorflow/models/blob/master/official/resnet/resnet_model.py) and [[2]](https://github.com/kefth/fashion-mnist/blob/master/model.py))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet v2\n",
    "def resnet_block(inputs, _filters, _strides=1, projection_shortcut=False): \n",
    "    out = tf.layers.batch_normalization(inputs, 1, _BATCH_NORM_DECAY, _BATCH_NORM_EPSILON,\n",
    "                                        training=is_training)\n",
    "    out = tf.nn.relu(out)\n",
    "    \n",
    "    if projection_shortcut:\n",
    "        shortcut = tf.layers.conv2d(out, _filters, 1, _strides, 'valid', 'channels_first', use_bias=False,\n",
    "                                    kernel_initializer=tf.variance_scaling_initializer())\n",
    "        print('use projection shortcut')\n",
    "    else:\n",
    "        shortcut = tf.identity(inputs)\n",
    "    print('shortcut shape : {}'.format(np.shape(shortcut)))\n",
    "    \n",
    "    # if stride is not 1, add 'little' padding\n",
    "    if not _strides == 1:\n",
    "        out = tf.pad(inputs, [[0, 0], [0, 0], [1, 1], [1, 1]])\n",
    "        # [[0, 0], [0, 0], [1, 1], [1, 1]] pad will added\n",
    "        # channels_first data format : [batch, channels, height_in, width_in]\n",
    "    else:\n",
    "        out = tf.identity(inputs)\n",
    "    \n",
    "    out = tf.layers.conv2d(out, _filters, 3, _strides,\n",
    "                           'same' if _strides == 1 else 'valid', 'channels_first',\n",
    "                           use_bias=False, kernel_initializer=tf.variance_scaling_initializer())\n",
    "    out = tf.layers.batch_normalization(out, 1, _BATCH_NORM_DECAY, _BATCH_NORM_EPSILON,\n",
    "                                           training=is_training)\n",
    "    out = tf.nn.relu(out)\n",
    "    out = tf.layers.conv2d(out, _filters, 3, 1, 'same', 'channels_first',\n",
    "                           use_bias=False, kernel_initializer=tf.variance_scaling_initializer())\n",
    "    out = tf.add(out, shortcut)\n",
    "    \n",
    "    print('ResNet block output shape : {}'.format(np.shape(out)))\n",
    "    return out\n",
    "\n",
    "def avg_pooling(inputs):\n",
    "    shape = inputs.get_shape().as_list()\n",
    "    in_channel = [shape[2], shape[3]] # if not channels_first, then (shape[1], shape[2])\n",
    "    \n",
    "    out = tf.layers.batch_normalization(inputs, 1, _BATCH_NORM_DECAY, _BATCH_NORM_EPSILON,\n",
    "                                           training=is_training)\n",
    "    out = tf.nn.relu(out)\n",
    "    out = tf.layers.average_pooling2d(out, in_channel, 1, 'valid', 'channels_first')\n",
    "    \n",
    "    print('Average pooling output shape : {}'.format(np.shape(out)))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape : (?, 1, 28, 28)\n",
      "shortcut shape : (?, 64, 28, 28)\n",
      "ResNet block output shape : (?, 64, 28, 28)\n",
      "shortcut shape : (?, 64, 28, 28)\n",
      "ResNet block output shape : (?, 64, 28, 28)\n",
      "use projection shortcut\n",
      "shortcut shape : (?, 128, 14, 14)\n",
      "ResNet block output shape : (?, 128, 14, 14)\n",
      "shortcut shape : (?, 128, 14, 14)\n",
      "ResNet block output shape : (?, 128, 14, 14)\n",
      "use projection shortcut\n",
      "shortcut shape : (?, 256, 7, 7)\n",
      "ResNet block output shape : (?, 256, 7, 7)\n",
      "shortcut shape : (?, 256, 7, 7)\n",
      "ResNet block output shape : (?, 256, 7, 7)\n",
      "Average pooling output shape : (?, 256, 1, 1)\n",
      "after flatten output shape : (?, 256)\n"
     ]
    }
   ],
   "source": [
    "# Resnet 18-layer like model for fashion mnist\n",
    "image = tf.reshape(tensor=x_image, shape=[-1, 28, 28, 1])\n",
    "\n",
    "# for boost GPU processing | change data format to NCHW (Tensorflow defalut is NHWC)\n",
    "resnet = tf.transpose(image, [0, 3, 1, 2])\n",
    "print('input shape : {}'.format(np.shape(resnet)))\n",
    "\n",
    "resnet = tf.layers.conv2d(resnet, 64, 3, 1, 'same', 'channels_first', use_bias=False, \n",
    "                          kernel_initializer=tf.variance_scaling_initializer())\n",
    "\n",
    "# 1st ResNet block \n",
    "resnet = resnet_block(resnet, 64)\n",
    "resnet = resnet_block(resnet, 64)\n",
    "# output shape [-1, 28, 28, 64]\n",
    "\n",
    "# 2nd ResNet block\n",
    "resnet = resnet_block(resnet, 128, 2, projection_shortcut=True)\n",
    "resnet = resnet_block(resnet, 128)\n",
    "# output shape [-1, 14, 14, 128]\n",
    "\n",
    "# 3rd ResNet block\n",
    "resnet = resnet_block(resnet, 256, 2, projection_shortcut=True)\n",
    "resnet = resnet_block(resnet, 256)\n",
    "# output shape [-1, 7, 7, 256]\n",
    "\n",
    "resnet = avg_pooling(resnet)\n",
    "# output shape [-1, 1, 1, 256]\n",
    "\n",
    "resnet = tf.layers.flatten(resnet)\n",
    "print('after flatten output shape : {}'.format(np.shape(resnet)))\n",
    "# output shape [-1, 256]\n",
    "logits = tf.layers.dense(resnet, n_classes, name='Logits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Loss Function / Optimizer / Prediction / Tensorboard scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('loss'):\n",
    "    entropy = tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_label, logits=logits)\n",
    "    loss = tf.reduce_mean(entropy, name='loss')\n",
    "\n",
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(update_ops):\n",
    "    optimizer = tf.train.AdamOptimizer(lr).minimize(loss)\n",
    "\n",
    "with tf.name_scope('predict'):\n",
    "    preds = tf.nn.softmax(logits)\n",
    "    correct_preds = tf.equal(tf.argmax(preds, 1), tf.argmax(y_label, 1))\n",
    "    accuracy = tf.reduce_sum(tf.cast(correct_preds, tf.float32))\n",
    "    \n",
    "with tf.name_scope('summaries'):\n",
    "    tf.summary.scalar('loss', loss)\n",
    "    tf.summary.scalar('accuracy', accuracy)\n",
    "    summary_op = tf.summary.merge_all()\n",
    "    \n",
    "saver = tf.train.Saver(tf.global_variables())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training & Test our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Start learning rate is 0.001 ---\n",
      "Epoch 1: loss = 0.009172 | Took : 47.1050 sec\n",
      "Validation Accuracy 0.7834\n",
      "Epoch 2: loss = 0.005780 | Took : 45.5730 sec\n",
      "Validation Accuracy 0.7880\n",
      "Epoch 3: loss = 0.004732 | Took : 47.1272 sec\n",
      "Validation Accuracy 0.8452\n",
      "Epoch 4: loss = 0.004225 | Took : 46.8768 sec\n",
      "Validation Accuracy 0.8478\n",
      "Epoch 5: loss = 0.003865 | Took : 44.4429 sec\n",
      "Validation Accuracy 0.8658\n",
      "Epoch 6: loss = 0.003644 | Took : 44.7682 sec\n",
      "Validation Accuracy 0.8850\n",
      "Epoch 7: loss = 0.003460 | Took : 44.7885 sec\n",
      "Validation Accuracy 0.8936\n",
      "Epoch 8: loss = 0.003352 | Took : 44.5969 sec\n",
      "Validation Accuracy 0.8836\n",
      "Epoch 9: loss = 0.003248 | Took : 44.2172 sec\n",
      "Validation Accuracy 0.8926\n",
      "Epoch 10: loss = 0.003132 | Took : 44.2866 sec\n",
      "Validation Accuracy 0.8980\n",
      "*** Test Accuracy 0.8903 ***\n",
      "Epoch 11: loss = 0.002996 | Took : 44.7303 sec\n",
      "Validation Accuracy 0.8882\n",
      "Epoch 12: loss = 0.002980 | Took : 44.2459 sec\n",
      "Validation Accuracy 0.8924\n",
      "Epoch 13: loss = 0.002916 | Took : 44.1897 sec\n",
      "Validation Accuracy 0.8920\n",
      "Epoch 14: loss = 0.002877 | Took : 44.2452 sec\n",
      "Validation Accuracy 0.8896\n",
      "Epoch 15: loss = 0.002783 | Took : 44.3466 sec\n",
      "Validation Accuracy 0.8974\n",
      "Epoch 16: loss = 0.002756 | Took : 44.1926 sec\n",
      "Validation Accuracy 0.9040\n",
      "Epoch 17: loss = 0.002684 | Took : 44.2481 sec\n",
      "Validation Accuracy 0.9128\n",
      "Epoch 18: loss = 0.002648 | Took : 45.1762 sec\n",
      "Validation Accuracy 0.9074\n",
      "Epoch 19: loss = 0.002605 | Took : 44.1926 sec\n",
      "Validation Accuracy 0.9104\n",
      "Epoch 20: loss = 0.002578 | Took : 44.2231 sec\n",
      "Validation Accuracy 0.9118\n",
      "*** Test Accuracy 0.9023 ***\n",
      "Epoch 21: loss = 0.002551 | Took : 44.0718 sec\n",
      "Validation Accuracy 0.9106\n",
      "Epoch 22: loss = 0.002498 | Took : 44.2385 sec\n",
      "Validation Accuracy 0.9118\n",
      "Epoch 23: loss = 0.002505 | Took : 44.1516 sec\n",
      "Validation Accuracy 0.9156\n",
      "Epoch 24: loss = 0.002468 | Took : 45.8196 sec\n",
      "Validation Accuracy 0.9100\n",
      "Epoch 25: loss = 0.002445 | Took : 46.0948 sec\n",
      "Validation Accuracy 0.9086\n",
      "Epoch 26: loss = 0.002393 | Took : 44.9566 sec\n",
      "Validation Accuracy 0.9110\n",
      "Epoch 27: loss = 0.002378 | Took : 44.6089 sec\n",
      "Validation Accuracy 0.9150\n",
      "Epoch 28: loss = 0.002367 | Took : 44.5901 sec\n",
      "Validation Accuracy 0.9080\n",
      "Epoch 29: loss = 0.002305 | Took : 45.7832 sec\n",
      "Validation Accuracy 0.9188\n",
      "Epoch 30: loss = 0.002295 | Took : 46.3199 sec\n",
      "Validation Accuracy 0.9166\n",
      "*** Test Accuracy 0.9104 ***\n",
      "Epoch 31: loss = 0.002335 | Took : 46.6785 sec\n",
      "Validation Accuracy 0.9094\n",
      "Epoch 32: loss = 0.002244 | Took : 46.3588 sec\n",
      "Validation Accuracy 0.9212\n",
      "Epoch 33: loss = 0.002257 | Took : 46.2612 sec\n",
      "Validation Accuracy 0.9130\n",
      "Epoch 34: loss = 0.002228 | Took : 46.6250 sec\n",
      "Validation Accuracy 0.9210\n",
      "Epoch 35: loss = 0.002215 | Took : 46.3449 sec\n",
      "Validation Accuracy 0.9232\n",
      "Epoch 36: loss = 0.002190 | Took : 46.1912 sec\n",
      "Validation Accuracy 0.9226\n",
      "Epoch 37: loss = 0.002210 | Took : 46.3433 sec\n",
      "Validation Accuracy 0.9178\n",
      "Epoch 38: loss = 0.002157 | Took : 46.3452 sec\n",
      "Validation Accuracy 0.9214\n",
      "Epoch 39: loss = 0.002134 | Took : 46.3106 sec\n",
      "Validation Accuracy 0.9210\n",
      "Epoch 40: loss = 0.002132 | Took : 46.2930 sec\n",
      "Validation Accuracy 0.9182\n",
      "*** Test Accuracy 0.9066 ***\n",
      "Epoch 41: loss = 0.002094 | Took : 46.2892 sec\n",
      "Validation Accuracy 0.9198\n",
      "Epoch 42: loss = 0.002093 | Took : 46.3385 sec\n",
      "Validation Accuracy 0.9210\n",
      "Epoch 43: loss = 0.002081 | Took : 46.2582 sec\n",
      "Validation Accuracy 0.9200\n",
      "Epoch 44: loss = 0.002062 | Took : 46.4727 sec\n",
      "Validation Accuracy 0.9176\n",
      "Epoch 45: loss = 0.002026 | Took : 46.1122 sec\n",
      "Validation Accuracy 0.9216\n",
      "Epoch 46: loss = 0.002036 | Took : 46.4764 sec\n",
      "Validation Accuracy 0.9196\n",
      "Epoch 47: loss = 0.001961 | Took : 45.3997 sec\n",
      "Validation Accuracy 0.9214\n",
      "Epoch 48: loss = 0.002022 | Took : 45.3629 sec\n",
      "Validation Accuracy 0.9236\n",
      "Epoch 49: loss = 0.001984 | Took : 45.2113 sec\n",
      "Validation Accuracy 0.9262\n",
      "Epoch 50: loss = 0.002000 | Took : 45.3446 sec\n",
      "Validation Accuracy 0.9232\n",
      "*** Test Accuracy 0.9141 ***\n",
      "Epoch 51: loss = 0.001969 | Took : 45.6606 sec\n",
      "Validation Accuracy 0.9292\n",
      "Epoch 52: loss = 0.001964 | Took : 45.3374 sec\n",
      "Validation Accuracy 0.9294\n",
      "Epoch 53: loss = 0.001956 | Took : 45.3099 sec\n",
      "Validation Accuracy 0.9264\n",
      "Epoch 54: loss = 0.001917 | Took : 45.2670 sec\n",
      "Validation Accuracy 0.9268\n",
      "Epoch 55: loss = 0.001935 | Took : 44.8442 sec\n",
      "Validation Accuracy 0.9256\n",
      "Epoch 56: loss = 0.001886 | Took : 47.4125 sec\n",
      "Validation Accuracy 0.9212\n",
      "Epoch 57: loss = 0.001895 | Took : 46.9799 sec\n",
      "Validation Accuracy 0.9334\n",
      "Epoch 58: loss = 0.001894 | Took : 46.3099 sec\n",
      "Validation Accuracy 0.9292\n",
      "Epoch 59: loss = 0.001857 | Took : 45.4889 sec\n",
      "Validation Accuracy 0.9310\n",
      "Epoch 60: loss = 0.001866 | Took : 45.7259 sec\n",
      "Validation Accuracy 0.9320\n",
      "*** Test Accuracy 0.9261 ***\n",
      "Epoch 61: loss = 0.001848 | Took : 45.5977 sec\n",
      "Validation Accuracy 0.9288\n",
      "Epoch 62: loss = 0.001849 | Took : 45.4730 sec\n",
      "Validation Accuracy 0.9232\n",
      "Epoch 63: loss = 0.001840 | Took : 44.0879 sec\n",
      "Validation Accuracy 0.9312\n",
      "Epoch 64: loss = 0.001836 | Took : 44.2588 sec\n",
      "Validation Accuracy 0.9304\n",
      "Epoch 65: loss = 0.001810 | Took : 43.9018 sec\n",
      "Validation Accuracy 0.9266\n",
      "Epoch 66: loss = 0.001803 | Took : 43.9942 sec\n",
      "Validation Accuracy 0.9250\n",
      "Epoch 67: loss = 0.001799 | Took : 43.9812 sec\n",
      "Validation Accuracy 0.9294\n",
      "Epoch 68: loss = 0.001800 | Took : 43.9767 sec\n",
      "Validation Accuracy 0.9302\n",
      "Epoch 69: loss = 0.001755 | Took : 44.0309 sec\n",
      "Validation Accuracy 0.9286\n",
      "Epoch 70: loss = 0.001780 | Took : 43.9287 sec\n",
      "Validation Accuracy 0.9304\n",
      "*** Test Accuracy 0.9201 ***\n",
      "Epoch 71: loss = 0.001760 | Took : 47.6085 sec\n",
      "Validation Accuracy 0.9284\n",
      "Epoch 72: loss = 0.001761 | Took : 45.0980 sec\n",
      "Validation Accuracy 0.9322\n",
      "Epoch 73: loss = 0.001781 | Took : 45.0020 sec\n",
      "Validation Accuracy 0.9342\n",
      "Epoch 74: loss = 0.001758 | Took : 45.3602 sec\n",
      "Validation Accuracy 0.9316\n",
      "Epoch 75: loss = 0.001736 | Took : 45.3034 sec\n",
      "Validation Accuracy 0.9280\n",
      "Epoch 76: loss = 0.001740 | Took : 45.2622 sec\n",
      "Validation Accuracy 0.9256\n",
      "Epoch 77: loss = 0.001719 | Took : 45.3152 sec\n",
      "Validation Accuracy 0.9364\n",
      "Epoch 78: loss = 0.001729 | Took : 46.1788 sec\n",
      "Validation Accuracy 0.9314\n",
      "Epoch 79: loss = 0.001711 | Took : 44.9622 sec\n",
      "Validation Accuracy 0.9308\n",
      "Epoch 80: loss = 0.001683 | Took : 45.0223 sec\n",
      "Validation Accuracy 0.9248\n",
      "*** Test Accuracy 0.9237 ***\n",
      "Epoch 81: loss = 0.001668 | Took : 44.6313 sec\n",
      "Validation Accuracy 0.9306\n",
      "Epoch 82: loss = 0.001710 | Took : 44.1444 sec\n",
      "Validation Accuracy 0.9294\n",
      "Epoch 83: loss = 0.001662 | Took : 45.5767 sec\n",
      "Validation Accuracy 0.9264\n",
      "Epoch 84: loss = 0.001678 | Took : 45.4843 sec\n",
      "Validation Accuracy 0.9222\n",
      "Epoch 85: loss = 0.001636 | Took : 44.7901 sec\n",
      "Validation Accuracy 0.9350\n",
      "Epoch 86: loss = 0.001653 | Took : 45.3496 sec\n",
      "Validation Accuracy 0.9266\n",
      "Epoch 87: loss = 0.001630 | Took : 45.0323 sec\n",
      "Validation Accuracy 0.9294\n",
      "Epoch 88: loss = 0.001643 | Took : 45.2115 sec\n",
      "Validation Accuracy 0.9264\n",
      "Epoch 89: loss = 0.001607 | Took : 45.2429 sec\n",
      "Validation Accuracy 0.9290\n",
      "Epoch 90: loss = 0.001616 | Took : 45.3851 sec\n",
      "Validation Accuracy 0.9338\n",
      "*** Test Accuracy 0.9265 ***\n",
      "Epoch 91: loss = 0.001605 | Took : 45.6195 sec\n",
      "Validation Accuracy 0.9260\n",
      "Epoch 92: loss = 0.001625 | Took : 45.4624 sec\n",
      "Validation Accuracy 0.9286\n",
      "Epoch 93: loss = 0.001611 | Took : 45.1864 sec\n",
      "Validation Accuracy 0.9300\n",
      "Epoch 94: loss = 0.001610 | Took : 45.6023 sec\n",
      "Validation Accuracy 0.9288\n",
      "Epoch 95: loss = 0.001586 | Took : 45.2370 sec\n",
      "Validation Accuracy 0.9332\n",
      "Epoch 96: loss = 0.001573 | Took : 45.3347 sec\n",
      "Validation Accuracy 0.9328\n",
      "Epoch 97: loss = 0.001583 | Took : 45.3797 sec\n",
      "Validation Accuracy 0.9308\n",
      "Epoch 98: loss = 0.001585 | Took : 45.3334 sec\n",
      "Validation Accuracy 0.9344\n",
      "Epoch 99: loss = 0.001563 | Took : 45.2813 sec\n",
      "Validation Accuracy 0.9272\n",
      "Epoch 100: loss = 0.001549 | Took : 45.2583 sec\n",
      "Validation Accuracy 0.9352\n",
      "*** Test Accuracy 0.9269 ***\n",
      "--- Decrease learning rate to 0.0001 ---\n",
      "Epoch 101: loss = 0.001551 | Took : 45.4888 sec\n",
      "Validation Accuracy 0.9354\n",
      "Epoch 102: loss = 0.001550 | Took : 45.2185 sec\n",
      "Validation Accuracy 0.9274\n",
      "Epoch 103: loss = 0.001532 | Took : 44.8516 sec\n",
      "Validation Accuracy 0.9290\n",
      "Epoch 104: loss = 0.001526 | Took : 46.2373 sec\n",
      "Validation Accuracy 0.9362\n",
      "Epoch 105: loss = 0.001532 | Took : 45.3535 sec\n",
      "Validation Accuracy 0.9314\n",
      "Epoch 106: loss = 0.001526 | Took : 45.2109 sec\n",
      "Validation Accuracy 0.9346\n",
      "Epoch 107: loss = 0.001485 | Took : 45.2625 sec\n",
      "Validation Accuracy 0.9360\n",
      "Epoch 108: loss = 0.001503 | Took : 45.2116 sec\n",
      "Validation Accuracy 0.9328\n",
      "Epoch 109: loss = 0.001521 | Took : 45.3082 sec\n",
      "Validation Accuracy 0.9294\n",
      "Epoch 110: loss = 0.001498 | Took : 45.2672 sec\n",
      "Validation Accuracy 0.9360\n",
      "*** Test Accuracy 0.9304 ***\n",
      "Epoch 111: loss = 0.001497 | Took : 46.7213 sec\n",
      "Validation Accuracy 0.9320\n",
      "Epoch 112: loss = 0.001485 | Took : 45.2133 sec\n",
      "Validation Accuracy 0.9362\n",
      "Epoch 113: loss = 0.001505 | Took : 45.2232 sec\n",
      "Validation Accuracy 0.9392\n",
      "Epoch 114: loss = 0.001486 | Took : 45.3238 sec\n",
      "Validation Accuracy 0.9402\n",
      "Epoch 115: loss = 0.001471 | Took : 45.4333 sec\n",
      "Validation Accuracy 0.9350\n",
      "Epoch 116: loss = 0.001488 | Took : 45.3569 sec\n",
      "Validation Accuracy 0.9340\n",
      "Epoch 117: loss = 0.001469 | Took : 45.9250 sec\n",
      "Validation Accuracy 0.9340\n",
      "Epoch 118: loss = 0.001448 | Took : 45.9699 sec\n",
      "Validation Accuracy 0.9222\n",
      "Epoch 119: loss = 0.001452 | Took : 45.2626 sec\n",
      "Validation Accuracy 0.9346\n",
      "Epoch 120: loss = 0.001459 | Took : 45.2423 sec\n",
      "Validation Accuracy 0.9354\n",
      "*** Test Accuracy 0.9232 ***\n",
      "Epoch 121: loss = 0.001453 | Took : 45.3155 sec\n",
      "Validation Accuracy 0.9340\n",
      "Epoch 122: loss = 0.001428 | Took : 45.6283 sec\n",
      "Validation Accuracy 0.9346\n",
      "Epoch 123: loss = 0.001456 | Took : 45.3743 sec\n",
      "Validation Accuracy 0.9358\n",
      "Epoch 124: loss = 0.001440 | Took : 45.7613 sec\n",
      "Validation Accuracy 0.9388\n",
      "Epoch 125: loss = 0.001423 | Took : 45.2180 sec\n",
      "Validation Accuracy 0.9332\n",
      "Epoch 126: loss = 0.001435 | Took : 45.4891 sec\n",
      "Validation Accuracy 0.9316\n",
      "Epoch 127: loss = 0.001439 | Took : 45.4816 sec\n",
      "Validation Accuracy 0.9372\n",
      "Epoch 128: loss = 0.001443 | Took : 44.8997 sec\n",
      "Validation Accuracy 0.9396\n",
      "Epoch 129: loss = 0.001408 | Took : 44.9342 sec\n",
      "Validation Accuracy 0.9394\n",
      "Epoch 130: loss = 0.001425 | Took : 45.6589 sec\n",
      "Validation Accuracy 0.9290\n",
      "*** Test Accuracy 0.9287 ***\n",
      "Epoch 131: loss = 0.001407 | Took : 47.1115 sec\n",
      "Validation Accuracy 0.9360\n",
      "Epoch 132: loss = 0.001418 | Took : 45.2922 sec\n",
      "Validation Accuracy 0.9346\n",
      "Epoch 133: loss = 0.001388 | Took : 45.1534 sec\n",
      "Validation Accuracy 0.9308\n",
      "Epoch 134: loss = 0.001393 | Took : 45.1799 sec\n",
      "Validation Accuracy 0.9302\n",
      "Epoch 135: loss = 0.001394 | Took : 45.1958 sec\n",
      "Validation Accuracy 0.9352\n",
      "Epoch 136: loss = 0.001402 | Took : 45.3933 sec\n",
      "Validation Accuracy 0.9376\n",
      "Epoch 137: loss = 0.001373 | Took : 45.5480 sec\n",
      "Validation Accuracy 0.9412\n",
      "Epoch 138: loss = 0.001377 | Took : 45.5122 sec\n",
      "Validation Accuracy 0.9302\n",
      "Epoch 139: loss = 0.001355 | Took : 45.2141 sec\n",
      "Validation Accuracy 0.9390\n",
      "Epoch 140: loss = 0.001402 | Took : 45.0892 sec\n",
      "Validation Accuracy 0.9328\n",
      "*** Test Accuracy 0.9284 ***\n",
      "Epoch 141: loss = 0.001369 | Took : 44.6722 sec\n",
      "Validation Accuracy 0.9386\n",
      "Epoch 142: loss = 0.001370 | Took : 44.7956 sec\n",
      "Validation Accuracy 0.9328\n",
      "Epoch 143: loss = 0.001348 | Took : 45.3162 sec\n",
      "Validation Accuracy 0.9382\n",
      "Epoch 144: loss = 0.001338 | Took : 45.1762 sec\n",
      "Validation Accuracy 0.9404\n",
      "Epoch 145: loss = 0.001352 | Took : 44.5808 sec\n",
      "Validation Accuracy 0.9340\n",
      "Epoch 146: loss = 0.001348 | Took : 44.7749 sec\n",
      "Validation Accuracy 0.9352\n",
      "Epoch 147: loss = 0.001361 | Took : 44.0250 sec\n",
      "Validation Accuracy 0.9358\n",
      "Epoch 148: loss = 0.001323 | Took : 44.0231 sec\n",
      "Validation Accuracy 0.9360\n",
      "Epoch 149: loss = 0.001346 | Took : 43.9936 sec\n",
      "Validation Accuracy 0.9356\n",
      "Epoch 150: loss = 0.001311 | Took : 43.9559 sec\n",
      "Validation Accuracy 0.9384\n",
      "*** Test Accuracy 0.9326 ***\n",
      "--- Decrease learning rate to 1e-05 ---\n",
      "Epoch 151: loss = 0.001303 | Took : 44.5420 sec\n",
      "Validation Accuracy 0.9378\n",
      "Epoch 152: loss = 0.001324 | Took : 43.9588 sec\n",
      "Validation Accuracy 0.9408\n",
      "Epoch 153: loss = 0.001315 | Took : 44.0229 sec\n",
      "Validation Accuracy 0.9354\n",
      "Epoch 154: loss = 0.001306 | Took : 44.0191 sec\n",
      "Validation Accuracy 0.9368\n",
      "Epoch 155: loss = 0.001305 | Took : 43.9333 sec\n",
      "Validation Accuracy 0.9356\n",
      "Epoch 156: loss = 0.001276 | Took : 44.0061 sec\n",
      "Validation Accuracy 0.9362\n",
      "Epoch 157: loss = 0.001335 | Took : 43.9322 sec\n",
      "Validation Accuracy 0.9352\n",
      "Epoch 158: loss = 0.001284 | Took : 44.6938 sec\n",
      "Validation Accuracy 0.9370\n",
      "Epoch 159: loss = 0.001285 | Took : 45.5410 sec\n",
      "Validation Accuracy 0.9366\n",
      "Epoch 160: loss = 0.001297 | Took : 45.4420 sec\n",
      "Validation Accuracy 0.9372\n",
      "*** Test Accuracy 0.9315 ***\n",
      "Epoch 161: loss = 0.001254 | Took : 57.9069 sec\n",
      "Validation Accuracy 0.9358\n",
      "Epoch 162: loss = 0.001276 | Took : 85.8938 sec\n",
      "Validation Accuracy 0.9372\n",
      "Epoch 163: loss = 0.001283 | Took : 85.8114 sec\n",
      "Validation Accuracy 0.9306\n",
      "Epoch 164: loss = 0.001288 | Took : 84.7531 sec\n",
      "Validation Accuracy 0.9404\n",
      "Epoch 165: loss = 0.001264 | Took : 84.8135 sec\n",
      "Validation Accuracy 0.9352\n",
      "Epoch 166: loss = 0.001255 | Took : 86.3334 sec\n",
      "Validation Accuracy 0.9376\n",
      "Epoch 167: loss = 0.001237 | Took : 85.9337 sec\n",
      "Validation Accuracy 0.9310\n",
      "Epoch 168: loss = 0.001247 | Took : 85.5472 sec\n",
      "Validation Accuracy 0.9370\n",
      "Epoch 169: loss = 0.001253 | Took : 86.1857 sec\n",
      "Validation Accuracy 0.9398\n",
      "Epoch 170: loss = 0.001248 | Took : 86.0531 sec\n",
      "Validation Accuracy 0.9388\n",
      "*** Test Accuracy 0.9365 ***\n",
      "Epoch 171: loss = 0.001220 | Took : 84.9649 sec\n",
      "Validation Accuracy 0.9348\n",
      "Epoch 172: loss = 0.001237 | Took : 85.7137 sec\n",
      "Validation Accuracy 0.9386\n",
      "Epoch 173: loss = 0.001236 | Took : 85.5484 sec\n",
      "Validation Accuracy 0.9346\n",
      "Epoch 174: loss = 0.001262 | Took : 85.6869 sec\n",
      "Validation Accuracy 0.9416\n",
      "Epoch 175: loss = 0.001227 | Took : 85.1693 sec\n",
      "Validation Accuracy 0.9314\n",
      "Epoch 176: loss = 0.001228 | Took : 85.8986 sec\n",
      "Validation Accuracy 0.9354\n",
      "Epoch 177: loss = 0.001231 | Took : 85.3273 sec\n",
      "Validation Accuracy 0.9414\n",
      "Epoch 178: loss = 0.001221 | Took : 86.3506 sec\n",
      "Validation Accuracy 0.9392\n",
      "Epoch 179: loss = 0.001287 | Took : 85.7638 sec\n",
      "Validation Accuracy 0.9364\n",
      "Epoch 180: loss = 0.001215 | Took : 84.1911 sec\n",
      "Validation Accuracy 0.9394\n",
      "*** Test Accuracy 0.9334 ***\n",
      "Epoch 181: loss = 0.001201 | Took : 84.4778 sec\n",
      "Validation Accuracy 0.9426\n",
      "Epoch 182: loss = 0.001179 | Took : 86.2302 sec\n",
      "Validation Accuracy 0.9446\n",
      "Epoch 183: loss = 0.001199 | Took : 85.1550 sec\n",
      "Validation Accuracy 0.9438\n",
      "Epoch 184: loss = 0.001204 | Took : 86.8609 sec\n",
      "Validation Accuracy 0.9344\n",
      "Epoch 185: loss = 0.001189 | Took : 85.1705 sec\n",
      "Validation Accuracy 0.9398\n",
      "Epoch 186: loss = 0.001200 | Took : 85.6990 sec\n",
      "Validation Accuracy 0.9376\n",
      "Epoch 187: loss = 0.001216 | Took : 83.8003 sec\n",
      "Validation Accuracy 0.9338\n",
      "Epoch 188: loss = 0.001204 | Took : 83.6827 sec\n",
      "Validation Accuracy 0.9404\n",
      "Epoch 189: loss = 0.001191 | Took : 83.8189 sec\n",
      "Validation Accuracy 0.9432\n",
      "Epoch 190: loss = 0.001199 | Took : 83.8069 sec\n",
      "Validation Accuracy 0.9378\n",
      "*** Test Accuracy 0.9334 ***\n",
      "Epoch 191: loss = 0.001170 | Took : 84.0629 sec\n",
      "Validation Accuracy 0.9406\n",
      "Epoch 192: loss = 0.001167 | Took : 83.8649 sec\n",
      "Validation Accuracy 0.9360\n",
      "Epoch 193: loss = 0.001157 | Took : 83.7621 sec\n",
      "Validation Accuracy 0.9378\n",
      "Epoch 194: loss = 0.001192 | Took : 83.8223 sec\n",
      "Validation Accuracy 0.9358\n",
      "Epoch 195: loss = 0.001165 | Took : 83.9225 sec\n",
      "Validation Accuracy 0.9398\n",
      "Epoch 196: loss = 0.001175 | Took : 83.7298 sec\n",
      "Validation Accuracy 0.9394\n",
      "Epoch 197: loss = 0.001146 | Took : 83.6934 sec\n",
      "Validation Accuracy 0.9390\n",
      "Epoch 198: loss = 0.001128 | Took : 83.8310 sec\n",
      "Validation Accuracy 0.9390\n",
      "Epoch 199: loss = 0.001144 | Took : 83.5126 sec\n",
      "Validation Accuracy 0.9394\n",
      "Epoch 200: loss = 0.001144 | Took : 83.7320 sec\n",
      "Validation Accuracy 0.9438\n",
      "*** Test Accuracy 0.9390 ***\n"
     ]
    }
   ],
   "source": [
    "total_epochs = 200\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    ckpt = tf.train.get_checkpoint_state('./model')\n",
    "    # if ckpt and tf.train.checkpoint_exists(ckpt.model_checkpoint_path):\n",
    "    #     saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "    # else:\n",
    "    #     sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    writer = tf.summary.FileWriter('./graphs/fashion_mnist', sess.graph)\n",
    "    print('--- Start learning rate is {} ---'.format(lr))\n",
    "    step = gstep.eval()\n",
    "\n",
    "    for i in range(total_epochs):\n",
    "        if i == (total_epochs * 0.5) or i == (total_epochs * 0.75):\n",
    "            lr = lr / 10\n",
    "            print('--- Decrease learning rate to {} ---'.format(lr))\n",
    "        \n",
    "        start_time = time.time()\n",
    "        train_aug_data = lambda: train_data.map(augmentation).shuffle(50000).batch(batch_size)\n",
    "        sess.run(train_init)\n",
    "        is_training = True\n",
    "        total_loss, n_batches = 0, 0\n",
    "        try:\n",
    "            while True:\n",
    "                _, l, summary = sess.run([optimizer, loss, summary_op])\n",
    "                writer.add_summary(summary, global_step=step)\n",
    "                step += 1\n",
    "                n_batches += 1\n",
    "                total_loss += l\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            pass\n",
    "        \n",
    "        print('Epoch {0}: loss = {1:0.6f} | Took : {2:0.4f} sec'.format(\n",
    "              i+1, total_loss/n_samples, time.time() - start_time))\n",
    "        \n",
    "        is_training = False\n",
    "        sess.run(val_init)\n",
    "        total_correct_train = 0\n",
    "        try:\n",
    "            while True:\n",
    "                accuracy_train, summaries = sess.run([accuracy, summary_op])\n",
    "                writer.add_summary(summaries, global_step=step)\n",
    "                total_correct_train += accuracy_train\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            pass\n",
    "        \n",
    "        print('Validation Accuracy {0:0.4f}'.format(total_correct_train/5000))\n",
    "        \n",
    "        if (i+1) % 10 == 0:\n",
    "            # for calculate test accuracy\n",
    "            sess.run(test_init)\n",
    "            total_correct_preds = 0\n",
    "            try:\n",
    "                while True:\n",
    "                    accuracy_test, summaries = sess.run([accuracy, summary_op])\n",
    "                    writer.add_summary(summaries, global_step=step)\n",
    "                    total_correct_preds += accuracy_test\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                pass\n",
    "        \n",
    "            print('*** Test Accuracy {0:0.4f} ***'.format(total_correct_preds/n_test))\n",
    "    \n",
    "    writer.close()\n",
    "    saver.save(sess=sess, save_path='./model/fmnist_resnet.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
